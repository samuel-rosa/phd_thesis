\artigotrue
\chapter{MODERN SOIL SPATIAL MODELLING AND ITS SOURCES OF UNCERTAINTY}
\shorttitle{Uncertainty in Soil Spatial Modelling}
\label{chap:chap02}

\def\enkeys{Demand for Soil Information. Mixed Model of Spatial Variation. Soil and Covariate Data. Model 
Structure}
  
\begin{chapterabstract}{english}{\enkeys}
The efforts of the soil science community have motivated the scientific community to recognize the importance 
of soils for humanity and the environment at the local, regional, and global levels. Soil spatial modellers 
seem to have been able to convince policy and decision makers about the importance of producing and updating 
soil information. For that end, soil spatial modellers have been using the mixed model of spatial variation 
(MMSV). The MMSV integrates aspects of \q{traditional} methods of soil spatial modelling, based on the discrete 
model of spatial variation (DMSV), as well of geostatistical techniques, more formally the continuous model of 
spatial variation (CMSV). As such, the MMSV explores the knowledge of soil-forming factors as well as the fact 
that the soil is a continuous media. It also acknowledges that soil maps \emph{always} deviate from the 
\q{truth}, which means that a soil map conveys what we expect the soil to be, not our certainty about it. 
There are many sources for our uncertainty about the soil. For instance, the soil and covariate data used to 
calibrate soil spatial models is an important source of uncertainty. Soil data can have errors and poorly 
represent the population from which it has been sampled. The influence of the covariate data on our 
uncertainty about the soil expresses itself through the poor correlation with soil properties. Finally, the 
structure of the model used to measure the empirical correlation between covariates and soil properties can 
greatly determined our uncertainty about the soil. Because we cannot eliminate the uncertainty of a soil map, 
our knowledge about the soil will \emph{always} be limited. Despite of this, soil spatial models are still 
needed to guide our every-day actions.
\end{chapterabstract}

\formatchapter

\section{DEMAND FOR SOIL SPATIAL INFORMATION}

\def\footmodeller{\footnote{The use that I give to the expression \emph{soil spatial modeller} throughout this 
thesis is approximately equivalent to expressions traditionally used in the academic world such as soil 
scientist, soil surveyor, soil taxonomist, geostatistician, pedometrician, soil investigator, soil mapper, and 
so on. In this thesis, a soil spatial modeller is any person that \emph{constructs} an explanation -- a model 
-- of the observed spatial soil variation using the tools and techniques available at his/her time and place. 
The goal of a soil spatial modeller is to construct a model that is simple yet able to produce an accurate 
representation of the spatial soil variation given the available resources and its intended application. I call 
this activity \emph{soil spatial modelling}. Accordingly, I understand that those that are excluded from the 
academic world such as peasants, farmers, indigenous populations, and so on, are soil spatial modellers as 
well, although their modelling of the soil is not the focus of this thesis.}}

Many soil spatial modellers\footmodeller{} have complained for many years about the decreasing interest in 
producing and updating soil information, not only in Brazil \cite{Dalmolin1999, Ker1999, KerEtAl2003, 
Mendonca-SantosEtAl2003, Ramos2003, Espindola2008, SamuelRosa2012}, but in many countries around the world 
\cite{Basher1997, HarteminkEtAl2008, Grunwald2009, SanchezEtAl2009, Finke2012}. Several reasons were presented 
to explain the general lack of interest in producing and updating soil information after the 1980s: the use of 
specialized taxonomic terminology by soil spatial modellers was abusive; information conveyed by soil maps was 
too limited due to its qualitative nature; policy and decision makers were unaware of the usefulness of soil 
information and dynamicity of soil; applied scientific research came to be preferred over basic scientific 
research; soil spatial modelling largely ignored environmental applications other than agriculture; lack of 
communication between soil spatial modellers and the general public; among others. But everyone seem to agree 
on one point: governments understood that producing and updating soil information was too costly. Cutting 
down the budget for soil spatial modelling fundamentally was an economic decision.

Since the last decade, soil scientists in general have launched many initiatives to make soil become a hot 
topic \cite{HarteminkEtAl2008}. For example, the United Nations (\WorldSoilDay) declared 5 December the World 
Soil Day and 2015 the International Year of Soils \cited{in an effort to raise awareness and promote more 
sustainable use of this critical resource}. Soil spatial modellers created a global consortium, the \gsm, with 
the goal of producing \cited{a new digital soil map of the world using state-of-the-art and emerging 
technologies}. The Food and Agriculture Organization (\fao) launched a Global Soil Partnership (\gsp) for 
\cited{leading to the adoption of sustainable development goals for soils}. The International Union of Soil 
Sciences (\iussusc) created a working group, funded by the United States Department of Agriculture (\usdausc) 
to develop a Universal Soil Classification System, \cited{a common language to describe soils that can be 
used internationally}. An Intergovernmental Technical Panel on Soils (\itps) was formed with soil experts from 
all regions of the world \cited{to provide scientific and technical advice and guidance on global soil issues 
to the Global Soil Partnership}. The \gates{} foundation handed out an \SI{18}[\$]~million grant \cited{to map 
most parts in Sub-Saharan Africa, and make all Sub-Saharan Africa soil data available}. Soil spatial modellers 
at the International Soil Reference and Information Centre (\isric) launched its Global Soil Information 
Facilities (\gsif), a \cited{framework for production of open soil data}, which has already output 
\SI{250}{\m}-resolution soil maps with global coverage. In Brazil, soil spatial modellers created the 
Brazilian Network for Research in Digital Soil Mapping (\redemds) with the objective of \cited{generating 
synergy among Brazilian soil scientists to advance research in digital soil mapping}.

\def\footpronassolos{\footnote{The initiative to restart the national soil survey program coincides with the 
currently increased, government funded, economically driven, historical pressure to occupy the Cerrado and 
Amazon biomes, considered \q{the last agricultural frontier} \cite{Correia2005, Macarini2005, Silva2005, 
CarvalhoEtAl2009, Batlle-BayerEtAl2010, MartinelliEtAl2010, SchneiderEtAl2015}. It is traditionally argumented 
that transforming parts of the Cerrado and Amazon biomes into agricultural land is needed to eradicate poverty 
in Brazil and to feed a growing world population. This is one of the argument used by the Brazilian 
politicians who are in favour of changing the Brazilian legislation to easy the acquisition of up to 
\SI{100000}{\hectare} of agricultural land in these regions by multinational corporations to produce cellulose 
and paper \cite{SECOM2015}. Unfortunately, the parts of the Brazilian territory that compose \q{the last 
agricultural frontier} suffer from severe social inequalities intensified by a long history of land conflicts 
fuelled by the conservative development model adopted in Brazil \cite{ComissaoPastoraldaTerra2015, 
SchneiderEtAl2015, Fernandes2016}, where the benefits of economic growth are not shared by all people. In 
regions such as this, the problem of food insecurity (and other societal problems) is likely more due to the 
lack of political will than to the lack of food \cite{FAO2005, FAO2009, FAO2015}. As such, one might wonder 
whether restarting the national soil survey program decoupled from a deep-cutting agrarian reform is beneficial
for the general Brazilian population.}}

The efforts of the soil science community have motivated the scientific community to recognize the importance 
of soils for humanity and the environment at the local, regional, and global levels \cite{SanchezEtAl2009, 
Kempen2011, OmutoEtAl2013}. Soil scientists, whose presence in public administration through scientific and 
technical advisory boards appears to grow, seem to have been able to convince policy and decision makers about 
the importance of producing and updating soil information. For example, in Brazil, the Federal Court of 
Accounts (\tcu), in collaboration with Embrapa Soils and other soil science related institutions, held a Soil 
Governance Conference, where a new National Program for Soil Survey and Interpretation of Brazil (\pronassolos)
was announced, with an expected budget of \SI{8}[R\$]~billion\footpronassolos. In the sequence, Embrapa Soils 
created a working group, with soil spatial modellers from other government institutions and universities, and 
the first PRONASOLOS report with proposal and goals was completed on December 2015. Unfortunately, it is not 
clear whether the national soil survey program will truly be restarted because, like happened in the end of the
1980s, it essentially is an economic decision. Apparently, other areas of soil science have not been receiving 
much more attention and/or funding than soil spatial modelling. It is also not clear whether the soil science 
community efforts have brought about a renewed recognition of the importance of soils for humanity and the 
environment among the general public.

\section{MODERN SOIL SPATIAL MODELLING}

Technology plays a determinant role on how we perceive the world around us -- see, for example, 
\citeonline{Hartemink2009}. When early farmers, during the Neolithic Revolution, ca.~\num{10000}~years ago, 
first observed that soil properties varied in space, they probably soon figured out that such variation was 
related to other environmental features and influenced crop yields. That early, rough, approximate 
understanding -- a \emph{model} -- of soil spatial variation certainly was fundamental for choosing -- 
\emph{predicting} -- the most appropriate locations to start and maintain human settlements, some of which 
became great, long-standing empires \cite{MazoyerEtAl2008, BrevikEtAl2010, Churchman2010}. Archaeological 
research provides evidence that several of these empires had more formal \emph{soil classification systems} and 
\emph{soil survey programs}, in most cases for taxation purposes \cite{Barrera-BassolsEtAl2003} -- a practice 
that lasts till today.

\def\footKubrick{\href{https://www.youtube.com/watch?v=qtbOmpTnyOc}{\textit{2001: A Space Odyssey}}}

%% Footnote %%%%%%%%%%%%%%%
\def\footsoil{\footnote{It is common sense among many soil scientists, not only in Brazil, 
that the activity of \emph{soil mapping} concerns the production of \emph{area-class soil maps}, also called 
\emph{polygon soil maps}, \emph{choropleth soil maps}, and more generally \emph{soil maps}. My view is that 
such an understanding, which is rooted in the fact that most early soil mapping projects aimed at producing 
area-class soil maps -- see \citet{Grunwald2009} for a discussion --, is erroneous. Multiple times it results 
in the confusion between the concept of soil itself and that of soil class, soil taxon and/or soil series. In 
this thesis a soil map is nothing more than a graphical representation of the soil. For that end, one has to 
choose a finite number of properties, characteristics, attributes, features of the soil -- the taxonomic 
classification is one such \emph{feature}. Thus, one must bear in mind that, throughout this thesis, the term 
\emph{soil} is used to mean \emph{soil} -- the uppermost layer of unconsolidated material of the Earth's 
surface... --, not soil class or soil taxon or soil series.}}

%% Footnote %%%%%%%%%%%%%%%
% Classes vs. properties: ‘Classes’ are categories of a pre-defined classification system or
% recognized during the survey as natural landscape elements; ‘properties’ are measurable Land
% Characteristics, e.g. soluble salts, or inferred Land Qualities, e.g. toxicity to a specific plant
% variety. \cite{Rossiter2000}

A lot happened since the Neolithic Revolution \cite{BrevikEtAl2010} -- from bone to spacecraft, as in 
Kubrick's \footKubrick{} --, and the knowledge constructed with multiple soil spatial studies was fundamental 
for the development of agriculture and increase of food production -- although many farmers still live in 
Neolithic conditions \cite{MazoyerEtAl2008}. If we adopt an integrative view, soil maps produced during this 
long period of human history seem to fit into what we call today the \emph{discrete model of spatial 
variation}. The discrete model of spatial variation explains the variation of soil properties in space 
using mutually exclusive mapping units that are separated by sharply defined, crisp boundaries (i.e. polygons) 
\cite{Heuvelink1996, Legros2006}. The soil\footsoil{} within each mapping unit is more or less homogeneous 
with regard to its properties at the time of mapping. These properties, which are generally used to name the 
mapping unit along with other environmental features, can be characterised using one or more direct 
observations made within the domain of the mapping unit \cite{WebsterEtAl1990, Rossiter2000, 
Legros2006}.

\subsection{Discrete Model of Spatial Variation}

A key step was given in 1886 in Russia with the formalization of the approximate understanding of the soil 
spatial variation using scientific parlance, i.e. the postulation of the \q{the basic law of soil science} by 
Vasily Dokuchaev \cite{Florinsky2012}: \q{Any... soil is always and everywhere a mere function of the following 
factors of soil formation: 1) the nature (content and structure) of the parent rock, 2) the climate of the 
given terrain, 3) the mass and character of vegetation, 4) the age of the terrain, and finally, 5) the terrain 
topography.}. The basic law of soil science was presented 40-years later by Sergey Zakharov in the form of a 
general soil formation equation, which is known in the western soil science literature as \cite{Jenny1941, 
Florinsky2012}

\begin{equation}\label{eqn:chap02-clorpt}
 soil = f(cl, o, r, p, t, \ldots),
\end{equation}

\noindent where $soil$ is the soil and its properties, $cl$ if the climate, $o$ are the organisms, including 
humans, $r$ stands for relief or topography, $p$ is the parent material, $t$ is time or age of the terrain, 
and $\ldots$ stand for other unknown players. Dokuchaev was aware that producing empirical evidence to 
corroborate his basic law of soil science was difficult because data on soil formation factors was scarce. 
Besides, it was difficult to numerically express the relation between soil and formation factors. Despite of 
these difficulties, the basic law of soil science was readily adopted by soil spatial modellers because it 
provided a solid basis for explaining the soil spatial variation \cite{Smith1986}.

An important enthusiast and supporter of the use of \autoref{eqn:chap02-clorpt} was Hans Jenny 
(\citeyear{Jenny1941}). He believed that the large volume of already existing soil data/knowledge, which had 
been constructed mostly based on the basic law of soil science, needed to be organized by means of numerical 
laws and quantitative theories -- instead of soil maps, taxonomic classifications, and soil-forming processes 
-- to enable treating it mathematically (i.e. using empirical correlation). For that end, solving 
\autoref{eqn:chap02-clorpt} depended on the soil scientist' skills to select suitable study areas and locations 
for making observations. But the problem continued to be that obtaining data on soil-forming factors was still 
difficult compared to obtaining soil data. It follows that direct application of \autoref{eqn:chap02-clorpt} 
for producing soil maps was impossible because it required soil-forming factors to be exhaustively known 
everywhere \cite{Jenny1941}. Despite the operational difficulties encountered since the postulation of the 
basic law of soil science and definition of \autoref{eqn:chap02-clorpt}, the concept of soil-forming factors 
were employed in most of the subsequent soil spatial studies around the world, resulting in the enhancement of 
taxonomic classifications, theories about soil-forming processes, and production of soil maps using the 
discrete model of spatial variation \cite{Schelling1970, Hudson1992, BockheimEtAl2000, Legros2006, 
KrasilnikovEtAl2009b, HarteminkEtAl2013}.

Soil spatial modelling using the discrete model of spatial variation and the idea that soil properties were 
determined by soil-forming factors had its weaknesses as any other model of spatial variation. Three main 
weaknesses can be pointed out, all of which only were recognized and understood using post-war 
scientific/technological developments \cite{HeuvelinkEtAl2001, McBratneyEtAl2003, ScullEtAl2003}. First, 
\q{soil bodies} were described as discrete, homogeneous entities -- although it was recognized that soil is a 
continuous media whose properties vary from place to place in such a way that nearby locations have more 
similar soil property values than distant locations (spatial autocorrelation) --, implying that the fluxes of 
energy and matter across the landscape had to be understood as being partially homogeneous (within a mapping 
unit), partially discontinuous (between mapping units) processes. Second, the uncertainty (the 
acknowledgement of errors) about mapped soil properties was disregarded, meaning that a single, absolute value 
for each soil property would be attributed to each mapping unit ignoring that soil properties vary from place 
to place and that estimates can be affected by all sorts of errors. Last, but not least, some important soil 
spatial modelling decisions could not be efficiently shared with others by means of formal, explicit knowledge 
because they were largely based on the intuitive, tacit knowledge of soil modellers, i.e. the knowledge that a 
soil modeller has about the soil-landscape relationships and the soil modelling process but that cannot be 
adequately communicated, articulated by verbal (written or spoken) means. This was evidenced, for example, by 
the fact that different soil modellers would produce considerably different soil maps without being able to 
explain why \cite{Legros2006, BazagliaFilhoEtAl2013}.

\subsection{Continuous Model of Spatial Variation}

Different solutions were explored during the post-war to overcome one or another weaknesses of the discrete 
model of spatial variation. Most of these solutions came from the new developments in the fields of 
mathematics, statistics and informatics. For example, those important soil spatial modelling decisions, 
generally taken with basis on the tacit knowledge of the soil modeller, could now be more efficiently 
communicated with others through the use of computers -- provided they had a computer. This is because using a 
computer to produce soil maps requires modelling rules to be formalized in the form of a computer script, 
which is the mean used to establish the communication between the soil modeller (a human being) and the data 
processing environment (a computer).

Some soil modellers also came to understand that the error about the mapped soil property could be 
acknowledged using classical statistical theory. First, the definition of mapping units, which was based on 
the knowledge of the soil-forming factors, needed to be viewed as a modelling exercise that aims at minimizing 
the within-unit variance (and maximizing the between-unit variance) of a soil property \cite{VoltzEtAl1990}. 
This was equivalent to designing controlled agronomic experiments as devised by Ronald Fisher in the United 
Kingdom during the 1920s, by which large plots and blocking are used to deal with the effects of short and 
long-range variation, respectively \cite{WebsterEtAl2007}. In both cases the spatial autocorrelation was 
regarded as being of little importance -- it still is in most agricultural experiments. Then, under the 
assumption of spatial independence within mapping units, the most likely value of a soil property at any one 
point in a given mapping unit would be its mean over the multiple observations made in that mapping unit 
\cite{VoltzEtAl1990, Cressie1993}. It follows that the uncertainty about the value of the mapped soil property
is the same everywhere within a mapping unit, irrespective of the location of existing soil observations 
\cite{Heuvelink1996}. This is because due to statistical independence and constant variance within mapping 
units, the expected error of predicting the value of a soil property at any location with its mean is also the
same everywhere. The only requirement so that the estimated mean and variance would be fair (unbiased) was 
that the location of soil observations be selected using some form of randomization (probability sampling) 
such as it is done in controlled agronomic experiments \cite{deGruijterEtAl1990}.

Those solutions still required describing \q{soil bodies} as discrete, homogeneous entities, and continued 
neglecting the spatial variation and autocorrelation of soil properties. Besides, despite the statistical 
soundness, most soil modellers fiercely rejected to employ random sampling and \emph{design-based} estimation. 
They have always preferred to select observation locations purposively according to their mental model of 
soil-landscape relationships because, from a pedological perspective, this seemed more reasonable. However, 
they were generally unaware of the biasedness of their \emph{model-based} estimates. For other soil spatial 
modellers a solution was to partially ignore the knowledge on soil-forming factors and use a different model 
of spatial variation: the \emph{continuous model of spatial variation}. Accordingly, the main requirement was 
that a soil property be treated as a regionalized variable, the outcome of a random (stochastic) spatial 
process \cite{Cressie1993, Webster2000}. A comprehensive theory of \emph{regionalized variables} was first 
constructed during the 1960s by the French mathematician Georges Matheron, heavily based on earlier studies of 
engineers, mathematician, meteorology and statistician such as the South African Daniel Krige, the Swedish 
Bertil Matérn, the Russian Andrey Kolmogorov, among others \cite{Krige1951, Matern1960, Matheron1965, 
MatheronEtAl1987, Cressie1990, WebsterEtAl2007}.

At first, the proposition of \emph{imagining} the soil as being the result of randomness is awkward (see, for 
example, \autoref{eqn:chap02-clorpt}). However, pondering on the multitude of soil-forming factors and 
processes, and on the complexity of their interactions \cite{BockheimEtAl2010, GrunwaldEtAl2011}, as well as 
on the limitations of the existing knowledge on soil spatial variation, one can easily conclude that soil is a 
chaotic media \cite{Webster2000} -- so why not treat it as such? One only had to \emph{imagine} that the value 
of a soil property observed at a given location simply was one that happened to be recorded by chance among an 
infinitely large number of values that could have been recorded instead \cite{Webster2000}. In other words, 
one had to \emph{imagine} that, if a soil property is recorded multiple times at the same location, the 
recorded values would not necessarily be the same. As such, a soil property at a given location would not be 
described using a single absolute value, but a probability distribution function (PDF), generally the normal 
(Gaussian), characterised by the mean and variance of those \q{recorded} values. Accordingly, to describe the 
fact that soil property values at nearby locations are more similar than at locations further apart -- they 
covary, vary together or jointly -- would require a joint probability distribution function, characterised by 
the covariance \cite{WebsterEtAl1990, Cressie1993}. The obvious difficulty in this approach is that the PDF 
cannot be defined because we usually have one single value recorded at each observation location.

Different from its discrete counterpart, the continuous model of spatial variation takes into account the 
relative location of existing observations when predicting a soil property at a given unobserved location. In 
the simplest case, the most likely value of a soil property in a given location is defined by a constant mean 
computed over all observations made in the mapping region, plus a random variable with mean zero and (spatial) 
covariance that depends only on the separation distance between locations \cite{WebsterEtAl1990, Cressie1993}.
This prediction method is known as the \emph{best linear unbiased predictor} (BLUP), usually called 
\emph{ordinary kriging}. The main idea underlying the continuous model of spatial variation is that soil 
property values at nearby locations are more similar than at locations further apart \cite{WebsterEtAl1990}. 
Thus, we err less if we predict the value of a soil property at a given location with a value observed at a 
nearby location than with a value observed at a distant location. Optimally, because the soil is a continuous 
media and its properties vary in space in an autocorrelated fashion, we make the most accurate prediction 
taking a weighted average of the values recorded at all observation locations, nearby locations receiving 
larger weights than distant locations. In both cases, it follows that the uncertainty about the mapped soil 
property is larger the farther from existing soil observations, i.e. it is spatially varying 
\cite{Cressie1993}.

\subsection{Mixed Model of Spatial Variation}

Availability of general-purpose computers fuelled the use and development of the continuous model of spatial 
variation, especially in European, North American, and Oceanian countries \cite{HeuvelinkEtAl2001, 
McBratneyEtAl2003, ScullEtAl2003}. But limitations in its prediction performance and developments in remote 
sensing and machine-learning algorithms helped many soil scientists to understand that the continuous model of
spatial variation had limitations too. For instance, it is unable to capture abrupt changes in the values of 
soil properties that occur, for example, between agricultural fields, parent materials, land uses, and so on
\cite{SteinEtAl1988, VoltzEtAl1990}. Because, compared to the discrete model of spatial variation, in its 
simplest form, the continuous model of spatial variation largely ignores the existing pedological knowledge
\cite{Grunwald2009, Lark2012}. Soil scientists also understood that the discrete model of spatial variation 
was more efficient than previously thought \cite{BregtEtAl1987, HeuvelinkEtAl2001}. First, because it was now
possible to employ the equation of soil-forming factors (\autoref{eqn:chap02-clorpt}) for soil mapping using 
remote sensing products as surrogates of the factors of soil formation \cite{MooreEtAl1993}. Second, 
machine-learning algorithms enabled identifying complex spatial patterns that before could only be identified 
by an experienced soil scientist \cite{McKenzieEtAl1999}. The most logical step was to combine the strengths 
of both discrete and continuous models of spatial variation into a single model -- the \emph{mixed model of 
spatial variation} --, that is, inclusion of the existing pedological knowledge and consideration of the 
spatial continuity of soil property values.

% Footnote
\def\footmixed{\footnote{The use that I give to the expression \emph{mixed model of spatial variation} in this 
thesis is approximately equivalent to expressions such as regression-kriging, kriging with external drift, 
universal kriging, hybrid approach for soil mapping, pedometric mapping, digital soil mapping, predictive soil 
mapping, environmental correlation, geostatistical mapping, soil-landscape modelling, and so on. As far as I 
know, soil spatial modellers have not yet reached an agreement on how these \q{traditional} expressions should 
be used, nor what their \q{correct} meaning is. See, for example, \citeonline{Hengl2003, McBratneyEtAl2003, 
ScullEtAl2003}. Because the expression \emph{mixed model of spatial variation} has a stronger theoretical 
basis (other expressions are defined based on operational aspects), I understand that its adoption and use is 
a more appropriate choice.}}

% Footnote
\def\footcovar{\footnote{In the statistical literature, the term \emph{covariate} is synonymous to 
\emph{explanatory variable}, \emph{predictor variable}, and \emph{independent variable}, and refers to the 
variable that, although not being of primary interest, is used in a model because it determines the behaviour 
of the \emph{response variable} or \emph{dependent variable} \cite{Everitt2006}. In soil science, a covariate 
has the same statistical meaning, the difference being that they assume a pedological meaning as well, i.e. 
they are viewed as proxies, indicators, substitutes, surrogates, approximations of the soil-forming factors 
due to the simple fact that the soil-forming factors -- the true environmental conditions that helped shape 
the soil -- are unknown and cannot be known. Covariates are defined \emph{spatially exhaustive} when they 
cover the entire area being modelled, i.e. they are exhaustively known in the entire geographic space.}}

The mixed model of spatial variation\footmixed{} can be viewed as a generalization of previously existing 
models of spatial variation, by which a soil property, here denoted $Y(\boldsymbol{s})$, at a given spatial 
location symbolised as $\boldsymbol{s}$ is modelled as the outcome of a spatial stochastic process 
\cite{Cressie1993, HeuvelinkEtAl2001, LarkEtAl2006}. Accordingly, the model is composed of \emph{fixed} and 
\emph{random effects}. The fixed effects, a deterministic large-scale spatial trend, denoted 
$m(\boldsymbol{s})$, describes the portion of the spatial variation of the soil property that is explained 
with the factors of soil formation as suggested by the empirical correlation calculated using point soil 
observations and spatially exhaustive covariates\footcovar. The random effects, also known as stochastic 
residuals or latent variables, denoted $e(\boldsymbol{s})$, describe the portion of the spatial variation of 
the soil property that cannot be explained with the covariates but is potentially spatially correlated, the 
form and degree of this spatial correlation possibly being interpreted pedologically \cite{Lark2012}. Thus 

\begin{equation}\label{eqn:intro-mixed-model}
Y(\boldsymbol{s}) = m(\boldsymbol{s}) + e(\boldsymbol{s}).
\end{equation}

\autoref{eqn:intro-mixed-model} possesses a great flexibility that facilitates to explore newly developed 
statistical and data-mining methods, generally resulting in better performance than the constituent models 
alone, as well as integrating the existing pedological knowledge provided it is translated into a mathematical 
form \cite{OdehEtAl1994, OdehEtAl1995, Heuvelink1996, McBratneyEtAl2000, HenglEtAl2004, Lopez-GranadosEtAl2005, 
WebsterEtAl2007, Grunwald2009, Lark2012}. These features promoted the rapid popularization of the mixed model 
of spatial variation, and many recent large scale soil-mapping projects already successfully employed the 
mixed model of spatial variation \cite{PoggioEtAl2014, NussbaumEtAl2014, HenglEtAl2015}.

% Unfortunately, along with the success of the mixed model of spatial variation, came a rupture between soil 
% modellers pertaining to different \q{schools}, building a negative atmosphere in many
% countries (see examples from Brazil [\url{https://groups.google.com/forum/#!forum/soil-mapping}] and
% Spain [\url{http://www.madrimasd.org/blogs/universo/2009/10/07/126094}]). On one side, this was
% caused by the (presumptuous) assumption that the mixed model of spatial variation possibly
% represented a \q{paradigm shift} in soil science \cite{McBratneyEtAl2003} and that it is the
% ultimate soil mapping method, superior to all others \cite{MinasnyEtAl2016}. This assumption is
% certainly untrue, specially in many poorer regions where the mixed model of spatial variation seems
% useless because farmers already obtain satisfactory yields and properly manage their soils using
% indigenous/local knowledge
% \cite{Barrera-BassolsEtAl2003, Barrera-BassolsEtAl2006, HillyerEtAl2006, CorreiaEtAl2007, 
% ValeJuniorEtAl2007}.
% Perhaps the strong criticism made against soil scientists that
% refused to adopt the mixed model of spatial variation, using somewhat pejorative arguments
% \cite{HeuvelinkEtAl2001,Mendonca-SantosEtAl2003}, helped building this unfruitful scenario. On
% the other side, soil scientists disliked losing importance in the research field in which they worked for
% decades, perhaps very afraid of the new technological developments due to their poor knowledge of
% mathematics, statistics, and informatics \cite{Webster2001,SamuelRosa2012}.

% Although all that is very common when a new theory or method appears
% \cite{Russell1932, Feyerabend1977, Kuhn2011}, I think we have reached a point in which nothing else
% can be gained by
% playing one soil scientist against the other. Such a (noble) understanding was already shared by
% \citeonline{Jenny1941} when comparing \cited{soil geographers} and \cited{soil functionalists}.

\subsection{Spatial Soil Modelling Steps}

Despite the rapid technological developments observed recently, the activity of modelling the soil remained 
essentially the same throughout human history. Soil maps still serve the same old purpose of representing our 
limited understanding about the spatial organization of the soil in the natural environment in a simplified 
manner, as well as giving insights about how the soil came to be and how they should be managed 
\cite{Jenny1941, Hudson1992, Legros2006, Blanco-CanquiEtAl2010, Grunwald2010}. For this reason, irrespective 
of the method/model used to produce soil maps, perhaps we should use an (integrative) expression such as 
\emph{soil spatial modelling} instead of picking one out of the many currently used.

It follows that, based on the existing body of knowledge on soil spatial modelling and the currently available 
technologies, we should try to define what it constitutes, in practice, the soil spatial modelling activity. A 
suggested general (didactic) sequence of eight steps that we believe represent what is or should be done in 
soil spatial modelling is presented below. The first step is numbered zero (0) to emphasize its importance: we
believe it to be a crucial step, where political, economical and paradigmatic decisions have to be made. Many
soil spatial modelling projects are not implemented because this first step is not completed.

\begin{description}
\item[Step 0] Identify a reality or problem entity, the geographic region for which there is a demand of 
spatial soil information. Target soil properties are appointed as well as the required accompanying output 
information (e.g. metadata). A minimum required accuracy level of the produced soil information can also be 
defined. Key modelling decisions are taken in this step such as the support (punctual or areal), spatial 
resolution (and possibly the cartographic scale), coordinate reference system, etc. Depending on how well 
defined the demand is, the model of spatial variation can also be specified, i.e. discrete, continuous, or 
mixed. Data policy is discussed (What data should be public? How to make data public? How to implement the 
data policy?) and agreed upon. Finally, the available infrastructure, budget, time, and workforce are 
specified so that next steps can be appropriately planned as to fulfil the demand.

\item[Step 1] Develop a conceptual model of pedogenesis, a verbal representation of the reality or problem 
entity including the explicit description of soil-forming factors and processes that determine the 
spatio-temporal distribution of soil properties. This requires gathering the most of the existing 
environmental information contained in scientific articles, technical reports, books, websites, local 
knowledge, as well as existing maps of the soil, land use, geology, digital elevation models, satellite 
images, aerial photographs, among others. Environmental information is used to articulate pedogenetic 
concepts. Provided that any of the existing soil data are available, an exploratory data analysis can help 
unravelling soil-landscape relationships. The poorer the volume of existing environmental information, and the 
less experienced the soil modeller is, the more important an exploratory field campaign is to help 
understanding the existing soil-landscape relationships.

\item[Step 2] Define the model of spatial variation, a translation of the conceptual model of pedogenesis into 
a set of possible mathematical representations. Depending on how well defined the demand was, the model of 
spatial variation was already specified in \textbf{Step 0}. Provided the volume of existing environmental 
information and legacy soil data is moderate to large and/or the soil modeller is very experienced and/or the 
available budget allows carrying out exploratory field campaigns, a single model of spatial variation is
defined, i.e. discrete, continuous, or mixed. Assuming that the mixed model of spatial variation is chosen, 
the statistical and/or data-mining models that will be used to represent the discrete and continuous 
components are specified, taking into account the feasibility of meeting their requirements given the 
available soil data, infrastructure, budget, time, and workforce. If multiple models or statistical and/or 
data-mining models are chosen, the pedological and statistical criteria for identifying the best performing 
model are defined.

\item[Step 3] Prepare the modelling database, a collection of soil and covariate data needed to estimate the 
parameters and test the chosen statistical and/or data-mining models. In some rare cases the modelling 
database is already available and does not require any further improvement. If this is the case, then this 
step would have already been covered in \textbf{Step 1}. However, in most cases this step requires preparing a
sampling plan with formally defined selection rules, making properly documented field soil observations, and 
running replicated laboratory analyses. Soil data from different sources are harmonized. Covariates are 
selected using the conceptual model of pedogenesis and empirical evidence. Both soil and covariate data are 
assessed regarding the need for nonlinear transformations to meet the requirements of the chosen statistical 
and/or data-mining models, and to improve their empirical correlation. Several of these tasks can be (and
usually are) carried out with the aid of a data processing environment (a computer).

\item[Step 4] Estimate the parameters of the statistical and/or data-mining models, a task that essentially 
depends on translating the set of possible mathematical representations of the conceptual model of pedogenesis 
into a computer representation, that is, a computer code or script. Developing a well documented computer code 
that describes all processing steps ease re-design, future consistency checks, correction of mistakes, and 
dissemination/reproducibility. Calibrated models are evaluated using statistical criteria defined in 
\textbf{Step 2} such as goodness-of-fit measures, as well as regarding their tenability (pedological 
evaluation). The latter includes visually assessing draft soil maps, and how well they represent the range of 
possible mathematical models. Failure in any of these evaluations suggests that the model requires adjustments,
possibly more calibration data, or that it can be discarded.

\item[Step 5] Validate the statistical and/or data-mining models, preferentially predicting the values of the 
modelled soil properties at a set of independent, probabilistically selected observation locations for which 
the true values are known. If an independent set of observation locations is unavailable, validation is 
performed using leave-one-out cross-validation. The best performing model is selected using the set of criteria
defined in \textbf{Step 2}: this is the best mathematical representation of the reality under study given the 
available data and knowledge. If two or more models present similar performance and have a considerably 
different structure, then (1) an aggregated version of these models is constructed or (2) parsimony is 
considered to elect the simpler model with fewer variables, steps, rules, etc. If previous steps have already 
allowed defining/selecting a single model, statistical validation is used only to assess model accuracy.

\item[Step 6] Make spatial predictions, the application of the best performing model(s) to predict soil 
properties values at unvisited locations in the entire modelling region. If demanded, the uncertainty about 
the predicted soil properties values (i.e. the prediction interval) is estimated too. Maps of the target soil 
properties as well as the required accompanying output information (e.g. point soil observations, covariate 
maps, uncertainty maps, metadata, computer scripts) are delivered to the users of the soil information, and 
possibly used to populate a spatial soil information system, where they are made available for inspection 
using different visualization techniques. Provided there is infrastructure, budget, time, and workforce 
available, modelling steps can be re-designed and the outputs updated at the user request.

\item[Step 7] Improve on the conceptual model of pedogenesis, the use of the knowledge gained during the 
previous steps until the production of the soil property maps, which give insights about the reality or problem
entity under study, to correct and/or improve the description of soil-forming factors and processes that 
determine the soil spatio-temporal distribution. If demanded, the reformulated conceptual model of pedogenesis 
is delivered to the users of the soil information as well to help in scenario analysis and decision making.
\end{description}

\section{SOURCES OF UNCERTAINTY IN SOIL SPATIAL MODELLING}

Soil spatial models, like any other model \cite{Box1976}, are nothing more than a simplification of reality. 
The reason for this is the fact that the existing knowledge and data are \emph{always} (very) limited -- we 
have to try our best with the available resources. This means that soil spatial models are unable to explain 
the spatial soil variation in its entirety, but only a small part of it \cite{Heuvelink1998a, Legros2006}. When 
we use a spatial soil model to produce continuous representations of soil properties across space, i.e. soil 
maps, these continuous representations will inexorably deviate from the \q{truth}. What the soil map presents 
is our most likely expectation about the soil properties -- not our \emph{certainty} about them. The deviation 
from the \q{truth} is what we call \emph{error}.

Many examples from the soil spatial modelling literature show that, irrespective of the soil property, spatial 
soil models have a quite variable predictive performance. In general, these models explain between 
\SI{15}{\percent} (or less) and (rarely more than) \SI{75}{\percent} of the soil spatial variation 
\cite{MooreEtAl1993, OdehEtAl1994, GesslerEtAl1995, McKenzieEtAl1999, GobinEtAl2001, SumflethEtAl2008, 
SunEtAl2012, ViscarraRosselEtAl2013, NussbaumEtAl2014, HenglEtAl2015, GaschEtAl2015, HeungEtAl2016}. Thus, 
because we cannot eliminate the uncertainty of a soil map, they can always be considered as wrong, the 
difference being that some might be useful.

\subsection{Soil Data}

Soil modellers aim at producing the most accurate representations of the soil given the available resources. 
Thus, a reasonable research program is the identification of the causes for soil maps being more or less 
accurate. For instance, the error that results from making extrapolations and interpolations to predict soil 
properties at unvisited locations is an important source of uncertainty \cite{HeuvelinkEtAl1999, 
RefsgaardEtAl2006}. In the case of data-centred soil models, such as the mixed model of spatial variation, 
these errors are larger the farther we are from the existing observations. Thus, the most efficient way of 
reducing these errors generally is to increase the number of observations and improve the spatial coverage of 
the mapping region \cite{BrusEtAl2007a}. However, most soil spatial modelling projects must rely on using only 
\emph{legacy} soil data, i.e. soil data produced many years or decades ago \cite{KempenEtAl2009, HenglEtAl2014,
PoggioEtAl2014, NussbaumEtAl2014, MulderEtAl2016}.

Legacy soil data have weaknesses that can affect prediction accuracy. For example, the size of the impact of 
using outdated soil data for predicting the current status of soil properties is unknown. However, we can 
expect that this impact will be larger on the accuracy of predictions of soil properties that are relatively 
more sensitive to land-use and climatic changes such as the organic carbon content. This is one of the reasons 
for the high uncertainty of global estimates of organic carbon storage in soils \cite{HenglEtAl2014}. A second 
weakness is the generally poor \q{quality} of soil legacy data for current uses. A poor quality arises from 
documentation inconsistencies, diversity of field and laboratory methods, use of different measurement units 
and nomenclature, absence of spatial positioning data, varying levels of precision and accuracy, among others 
\cite{RibeiroEtAl2015}. As for the use of outdated data, how much the use of non-standardised and 
non-harmonised soil data affects soil spatial predictions remains unknown. Finally, legacy soil data can poorly
represent the mapping region due to bias in the selection of observations locations. This location bias comes 
from soil modellers sampling preferentially in complex and less known areas (to gain knowledge of 
soil-landscape relationships) or by convenience in most easy access areas (to optimize the use of the available
resources) \cite{Rossiter2000, deGruijterEtAl2006}.

Some times the budget of the soil spatial modelling project (fortunately) includes (additional) sampling. 
Then soil modellers have to decide upon the number and spatial configuration of the sample 
\cite{deGruijterEtAl2006, WebsterEtAl2013}. But this is not an easy task, except if the goal is on modelling 
very few soil properties that can be rapidly measured using field sensors, and for which a model of spatial 
(co)variation can be assumed known \cite{MarchantEtAl2006}. In most cases, several difficult-to-measure soil 
properties have to be modelled, many of which have a poorly known structure of spatial (co)variation. If using 
the mixed model of spatial variation, the chosen spatial sample configuration has to be appropriate for 
estimating the spatial trend \cite{HenglEtAl2003a, MinasnyEtAl2006b} and the variogram model 
\cite{WarrickEtAl1987, WebsterEtAl1992, Lark2002}, making spatial predictions \cite{YfantisEtAl1987, 
WalvoortEtAl2010} and, (cross)validating spatial predictions \cite{BrusEtAl2011}, four often conflicting 
objectives. Besides, one must be careful not to decide upon collecting an insufficient or an exaggerated number
of soil samples. Under-sampling can result in soil models with large uncertainty, while over-sampling can 
produce modelling benefits that do not outweigh the sampling costs \cite{vanGroenigenEtAl1999}.

% Footnote %%%%%
\def\footfeature{\footnote{The \emph{feature space}, also known as \emph{attribute space}, is the 
multi-dimensional mathematical space defined by the set of covariates used in a soil spatial modelling 
exercise. Specifically, if the number of covariates is equal to \textit{p}, then the feature space is a 
\textit{p}-dimensional mathematical space. In contrast, the \emph{geographic space} is the bi-dimensional 
mathematical space defined by the geographic coordinates of the mapping region. Both spaces are \emph{finite} 
in the sense that they are bounded by the set of geographic coordinates that define the geographic limits of 
the study area (or mapping region) and any existing non-mapping area. However, while the feature space is a 
\emph{discrete space} -- the set of possible values attributed to the covariates is limited to the set of 
known existing covariate values --, the geographic space is a \emph{continuous space} -- any pair of values 
can be attributed to the geographic coordinates provided it is bounded by the geographic limits of the study 
area and any existing non-mapping area.}}

Soil data can uniformly cover the geographic and/or feature spaces\footfeature{}, but at an observation 
density that still is unable to capture the main structures of correlated spatial variation of a soil property.
This is likely to happen when the range of correlated spatial variation is relatively short (small scale 
variation) compared to the size of the mapping region (large scale variation) \cite{Burrough1983}. Soil data 
can also have significant laboratory and positional errors \cite{NelsonEtAl2011}. Besides, data on some soil 
properties may naturally contain more errors due to conceptual definitions and analytical procedures employed. 
Take particle-size distribution as an example. First, the errors are propagated to the fraction obtained by 
difference (silt). Second, pre-treatments, such as organic matter oxidation, can change mineral structure 
\cite{MikuttaEtAl2005a}. And third, ignoring that the particle-size distribution is a compositional datum can 
introduce bias in the predictions \cite{LarkEtAl2007}.

\subsection{Covariate Data}

Another important source of uncertainty is the covariate data used to calibrate the soil models. Their effect 
appears as a poor correlation with soil properties being modelled, resulting in poor predictions. Several are 
the possible reasons for the covariate data to be poorly correlated with the soil property. One of the them is 
the fact that the covariate data also contain varying levels of error \cite{HeuvelinkEtAl1989} which could 
make them poor proxies of the soil-forming factors. These errors derive from the various methods of data 
generation, analytical procedures and, inherent characteristics of each site. For example, digital elevation 
models usually present larger errors in areas with steep slopes, rough terrains, and high altitude, and with 
dense forest cover or urbanized \cite{Florinsky1998, Toutin2000, FisherEtAl2006}. Interpolation of elevation 
data using kriging can produce spurious artefacts \cite{HenglEtAl2009} compared to hydrologically consistent 
algorithms \cite{Hutchinson1989}. And stereoscopic correlation techniques generally produce digital elevation 
models with poorer quality than interferometric synthetic aperture radar \cite{HirtEtAl2010}.

The method used to select which covariates to include in the soil spatial model can also be a reason for soil 
maps to be in more or less error. This is because every method can select considerably different sets of 
covariates, perhaps including a few that are poorly correlated with soil properties. The selection of 
covariates is especially important because the number of available (uncertain) covariates is large, many of 
which possibly being statistically redundant. 

A pedologically sound approach for the selection of covariates is the elicitation of the knowledge of a 
few experts \cite{LarkEtAl2007a, MeyerEtAl2001}. An expert is every soil modeller with long-term practical 
experience in soil spatial modelling and deep knowledge of the mapping region, as expressed in the conceptual 
model of pedogenesis, as well as of the soil and covariate data. However, it may be that the understanding 
about the mapping region may be limited to a point that enables building only a very poor conceptual model of 
pedogenesis. Take for example a geomorphologically complex, unstable landscape that consistently suffers from 
natural and/or anthropogenic alterations. Establishing soil-landscape relationships is very difficult in such 
circumstances, especially if the geomorphological complexity is increased as the landscape is rejuvenated 
\cite{StreckEtAl2008}. Similar uncertainty regarding the soil-landscape relationships can arise in very old, 
stable surfaces of the tropics that have gone through many environmental modifications, but were not affected 
by Pleistocene glaciations \cite{MckenzieEtAl2006}. These landscapes commonly have polygenetic soils that 
present properties reflecting today and ancient vegetation and climate \cite{PainEtAl1995, Ker1998}. One could 
wonder whether expert soil modellers would be more efficient at identifying the covariates with the highest 
predictive power than sound statistical inference in such circumstances.

A commonly used approach to select the covariates to enter a soil spatial model is automated selection. 
Automated covariate selection algorithms have always been relatively easy to use \cite{DraperEtAl1971} and are 
available in most software packages \cite{Harrell2001a}. They generally deliver satisfactory results and are 
needed to automate soil spatial modelling routines \cite{HenglEtAl2014}. Each of them employs different search 
strategies. For example, some methods analyse all possible combinations of covariates. Others simulate the 
process of natural selection \cite{AndersenEtAl2010}. Cross-validation selects covariates that produce the best 
predictions on test sets \cite{GuyonEtAl2003}. Other methods take into account the order in which the 
covariates are added to (forward selection) or removed from (backward elimination) the model 
\cite{LarkEtAl2007a}. The stepwise method adds and removes covariates until no further addition or removal 
results in significant changes in the model \cite{DraperEtAl1998}. Some prefer to use dimensionality reduction 
techniques to reduce the number of covariates \cite{Massy1965} before running the covariate selection algorithm 
\cite{tenCatenEtAl2011a, HenglEtAl2014}. Several other methods exist and have been used in soil spatial 
modelling \cite{PoggioEtAl2013, NussbaumEtAl2014}. Because each algorithm employs a different search 
strategy, they generally select different sets of covariates possibly with varying degrees of correlation 
with the soil property being modelled. The best covariate selection algorithm can be identified, for example, 
using sound statistical inference made on external validation data. However, this is rarely done and the most 
popular algorithm, or that implemented in the available software package is used. Besides, there are evidences 
that the number of problems associated with using automated covariate selection methods, and dimensionality 
reduction techniques, can be greater than the number of advantages \cite{FarrarEtAl1967, Jackson1993, 
Chatfield1995, Edirisooriya1995, Harrell2001a, Jolliffe2002, Peres-NetoEtAl2005, LarkEtAl2007a, Ratner2010}.

Despite the difficulties associated with using uncertain covariates and automated selection algorithms, 
their contribution to the error in soil spatial modelling is poorly understood. For example, more accurate 
covariate data may not necessarily be a better proxy of the soil-forming factors. In very old and stable 
surfaces of the tropics such as described above, current soil properties are more due to past than to present 
environmental conditions. Present day covariate data are not indicators of such environmental conditions. 
Indeed, \q{degrading} the accuracy of the covariates to produce multiple representations of the landscape from 
moderate to large spatial scales can yield more accurate predictions \cite{BehrensEtAl2010a}. However, this 
multiplies the number of covariates, increasing the need to better understand the effects of using automated 
selection algorithms in soil spatial modelling.

\subsection{Model Structure}

Soil modellers also have to chose the form of the model that will be used to model the
empirical relation between covariates and soil properties. Early soil-mapping projects were based
solely on mental models \cite{Hudson1992}. Later, many soil-mapping projects used statistical
models that assume a linear relation \cite{MooreEtAl1993, OdehEtAl1994}. Developments in
statistics introduced new forms of modelling this relation. Nowadays many soil-mapping projects
employ machine-learning methods such as regression trees, artificial neural networks, random forests,
support vector machines, among many others \cite{HeungEtAl2016}. The main reason being that these
nonlinear models have a greater ability to capture more complex site-specific soil-landscape relations
\cite{Grunwald2009}.

In fact, the relation between soil properties and covariates seldom is completely linear 
\cite{McKenzieEtAl1999}. For some the fact that each model produces a
different soil map may be seen as a problem, although the validation statistics may suggest that the 
differences in their performance are insignificant \cite{HeungEtAl2016}. A solution is to aggregate 
the predictions of the many models, but this will not necessarily reduce our uncertainty. Besides, 
machine-learning methods are more difficult to implement and interpret \cite{Grunwald2009}, possibly 
being more prone to error.

\section{CONCLUSIONS}

The sources of uncertainty in soil spatial modelling are multiple and the list that has been presented here
is far from being comprehensive -- others will do a better job. The main message is that we cannot 
eliminate the uncertainty of a soil map and, as such, our knowledge about the soil will always
be limited. Despite of this, soil spatial models -- and the entire body of human knowledge -- are still
needed to guide our every-day actions. So, instead of eliminating uncertainty, the real quest is for
understanding it and its sources. If for instance it happens to us to gain knowledge that a source of 
error has a systematic nature, then a corrective measure can be taken right away.

% Because while studying the multiple sources of uncertainty -- the
% \emph{known unknowns} --, instead of bringing them all into light, turning them into sources of 
% error which we have a good understanding of -- the \emph{known knowns} --, we end up uncovering 
% other sources of error that we were not aware of -- the \emph{unknown unknowns} \cite{Wikipedia2015}. 
% If a known (or unknown) unknown happens to become a known known, then action can be taken to 
% reduce our uncertainty. For example, if we gain knowledge that a source of error has a systematic nature, 
% then a corrective measure can be taken right away.

A most comprehensive way of dealing with the multiple sources of uncertainty is \emph{error propagation 
analysis}, also called \emph{uncertainty analysis} \cite{HeuvelinkEtAl1989, Taylor1997}. This is done taking
our uncertainty into account through the modelling steps, seeing how it propagates, and
evaluating its impact on the uncertainty about the output soil map. This would allow us identifying the
main source of uncertainty, so that we could try to take corrective measures to improve its quality.
But such an exercise is cumbersome \cite{NelsonEtAl2011}, and the efforts required may not
outweigh the benefits, this being one of the reasons why it is rarely carried out. Another important
reason for error propagation analysis being unpopular is the common ignorance and lack of
understanding -- perhaps prejudice -- about error and uncertainty \cite{Wechsler2003, Heuvelink2005}.
But the most important reason seems to be that statistical packages and data analysis environments do
not include -- if they ever will or should include -- a simple routine, a button, to run a complete
uncertainty analysis \cite{HeuvelinkEtAl2006b}.

%Since soil maps still are useful, despite being in error, most soil-mapping projects adopt a very
%pragmatic approach, and the uncertainty is almost completely ignored \cite{McBratneyEtAl2003, 
%ScullEtAl2003}.
%In other words, we assume that all sources of uncertainty are insignificant.
%Positional and analytical errors are disregarded, covariates are taken as certain, and so on. These
%data are used to calibrate a few models, whose parameters are assumed to be estimated without error
%\cite{DiggleEtAl1998}. The soil-mapping model with the best validation statistics, generally
%chosen using (the optimistic) cross-validation, is selected to make spatial predictions at unvisited
%locations \cite{BrusEtAl2011}. Errors in the resulting map are regarded as being due to interpolation
%error. Most soil models will output an estimate of this uncertainty, i.e. a measure of what
%we do not know about the modelled/mapped soil property such as the kriging prediction error variance
%\cite{HeuvelinkEtAl1989}. But even such a measure is nothing more than a model of our uncertainty
%whose quality needs proper assessment \cite{Goovaerts2001}. Because soil models that ignore
%the spatial autocorrelation of the prediction errors generally are optimistic about our uncertainty,
%i.e. they estimate that we know more than we actually do. And geostatistical models can either
%under- or overestimate the uncertainty depending on the available data and modelling decisions
%\cite{Lark2000a}.

%Continually ignoring the uncertainty in soil-mapping projects is quite a dangerous choice
%\cite{HeuvelinkEtAl1999}. It can induce the layman -- and even other scientists -- to think that
%soil modellers produce perfect, complete answers to soil-related issues. The most likely
%consequence is what already happened in the end of the 1980's in most countries when funds for
%soil-modelling research were almost completely extinguished
%\cite{Basher1997, Dalmolin1999, Ker1999, Ramos2003, HarteminkEtAl2008, Finke2012}: if the
% soil map is a perfect
%representation of reality, then once it is done, soil modellers become useless. Nowadays, many
%software packages and data analysis environments include a basic routine to take into account, at
%least, one source of uncertainty \cite{ChristensenEtAl2002, Papritz2015, RibeiroJrEtAl2015}. If a
%more elaborated, problem-specific software is required, then there is the free and open source
%software community. Free access to the scientific literature is guaranteed by many governments,
%universities, and libraries that spend a significant amount of resources every year on subscriptions
%and maintenance of digital repositories. Anyone with a true interest in contributing to the body of
%human knowledge must recognize the urgent need to stop neglecting, perhaps consciously denying, 
%what we already known -- the \emph{unknown knowns} \cite{Zizek2006}.

