\artigotrue
\chapter{MODERN SOIL SPATIAL MODELLING AND ITS SOURCES OF UNCERTAINTY}
\shorttitle{Uncertainty in Soil Spatial Modelling}
\label{chap:chap02}

\def\enkeys{Demand for Soil Information. Mixed Model of Spatial Variation. Soil and Covariate Data. Model 
Structure}
  
\begin{chapterabstract}{english}{\enkeys}
The efforts of the soil science community have motivated the scientific community to recognize the importance 
of soils for humanity and the environment at the local, regional, and global levels. Soil spatial modellers 
seem to have been able to convince policy and decision makers about the importance of producing and updating 
soil information. For that end, soil spatial modellers have been using the mixed model of spatial variation 
(MMSV). The MMSV integrates aspects of \q{traditional} methods of soil spatial modelling, based on the discrete 
model of spatial variation (DMSV), as well of geostatistical techniques, more formally the continuous model of 
spatial variation (CMSV). As such, the MMSV explores the knowledge of soil-forming factors as well as the fact 
that the soil is a continuous media. It also acknowledges that soil maps \emph{always} deviate from the 
\q{truth}, which means that a soil map conveys what we expect the soil to be, not our certainty about it. 
There are many sources for our uncertainty about the soil. For instance, the soil and covariate data used to 
calibrate soil spatial models is an important source of uncertainty. Soil data can have errors and poorly 
represent the population from which it has been sampled. The influence of the covariate data on our 
uncertainty about the soil expresses itself through the poor correlation with soil properties. Finally, the 
structure of the model used to measure the empirical correlation between covariates and soil properties can 
greatly determined our uncertainty about the soil. Because we cannot eliminate the uncertainty of a soil map, 
our knowledge about the soil will \emph{always} be limited. Despite of this, soil spatial models are still 
needed to guide our every-day actions.
\end{chapterabstract}

\formatchapter

\section{DEMAND FOR SOIL SPATIAL INFORMATION}

\def\footmodeller{\footnote{The use that I give to the expression \emph{soil spatial modeller} throughout this 
thesis is approximately equivalent to expressions traditionally used in the academic world such as soil 
scientist, soil surveyor, soil taxonomist, geostatistician, pedometrician, soil investigator, soil mapper, and 
so on. In this thesis, a soil spatial modeller is any person that \emph{constructs} an explanation -- a model 
-- of the observed spatial soil variation using the tools and techniques available at his/her time and place. 
The goal of a soil spatial modeller is to construct a model that is simple yet able to produce an accurate 
representation of the spatial soil variation given the available resources and its intended application. I call 
this activity \emph{soil spatial modelling}. Accordingly, I understand that those that are excluded from the 
academic world such as peasants, farmers, indigenous populations, and so on, are soil spatial modellers as 
well, although their modelling of the soil is not the focus of this thesis.}}

Many soil spatial modellers\footmodeller{} have complained for many years about the decreasing interest in 
producing and updating soil information, not only in Brazil \cite{Dalmolin1999, Ker1999, KerEtAl2003, 
Mendonca-SantosEtAl2003, Ramos2003, Espindola2008, SamuelRosa2012}, but in many countries around the world 
\cite{Basher1997, HarteminkEtAl2008, Grunwald2009, SanchezEtAl2009, Finke2012}. Several reasons were presented 
to explain the general lack of interest in producing and updating soil information after the 1980s: the use of 
specialized taxonomic terminology by soil spatial modellers was abusive; information conveyed by soil maps was 
too limited due to its qualitative nature; policy and decision makers were unaware of the usefulness of soil 
information and dynamicity of soil; applied scientific research came to be preferred over basic scientific 
research; soil spatial modelling largely ignored environmental applications other than agriculture; lack of 
communication between soil spatial modellers and the general public; among others. But everyone seem to agree 
on one point: governments understood that producing and updating soil information was too costly. Cutting 
down the budget for soil spatial modelling fundamentally was an economic decision.

Since the last decade, soil scientists in general have launched many initiatives to make soil become a hot 
topic \cite{HarteminkEtAl2008}. For example, the United Nations (\WorldSoilDay) declared 5 December the World 
Soil Day and 2015 the International Year of Soils \cited{in an effort to raise awareness and promote more 
sustainable use of this critical resource}. Soil spatial modellers created a global consortium, the \gsm, with 
the goal of producing \cited{a new digital soil map of the world using state-of-the-art and emerging 
technologies}. The Food and Agriculture Organization (\fao) launched a Global Soil Partnership (\gsp) for 
\cited{leading to the adoption of sustainable development goals for soils}. The International Union of Soil 
Sciences (\iussusc) created a working group, funded by the United States Department of Agriculture (\usdausc) 
to develop a Universal Soil Classification System, \cited{a common language to describe soils that can be 
used internationally}. An Intergovernmental Technical Panel on Soils (\itps) was formed with soil experts from 
all regions of the world \cited{to provide scientific and technical advice and guidance on global soil issues 
to the Global Soil Partnership}. The \gates{} foundation handed out an \SI{18}[\$]~million grant \cited{to map 
most parts in Sub-Saharan Africa, and make all Sub-Saharan Africa soil data available}. Soil spatial modellers 
at the International Soil Reference and Information Centre (\isric) launched its Global Soil Information 
Facilities (\gsif), a \cited{framework for production of open soil data}, which has already output 
\SI{250}{\m}-resolution soil maps with global coverage. In Brazil, soil spatial modellers created the 
Brazilian Network for Research in Digital Soil Mapping (\redemds) with the objective of \cited{generating 
synergy among Brazilian soil scientists to advance research in digital soil mapping}.

\def\footpronassolos{\footnote{The initiative to restart the national soil survey program coincides with the 
currently increased, government funded, economically driven, historical pressure to occupy the Cerrado and 
Amazon biomes, considered \q{the last agricultural frontier} \cite{Correia2005, Macarini2005, Silva2005, 
CarvalhoEtAl2009, Batlle-BayerEtAl2010, MartinelliEtAl2010, SchneiderEtAl2015}. It is traditionally argumented 
that transforming parts of the Cerrado and Amazon biomes into agricultural land is needed to eradicate poverty 
in Brazil and to feed a growing world population. This is one of the argument used by the Brazilian 
politicians who are in favour of changing the Brazilian legislation to easy the acquisition of up to 
\SI{100000}{\hectare} of agricultural land in these regions by multinational corporations to produce cellulose 
and paper \cite{SECOM2015}. Unfortunately, the parts of the Brazilian territory that compose \q{the last 
agricultural frontier} suffer from severe social inequalities intensified by a long history of land conflicts 
fuelled by the conservative development model adopted in Brazil \cite{ComissaoPastoraldaTerra2015, 
SchneiderEtAl2015, Fernandes2016}, where the benefits of economic growth are not shared by all people. In 
regions such as this, the problem of food insecurity (and other societal problems) is likely more due to the 
lack of political will than to the lack of food \cite{FAO2005, FAO2009, FAO2015}. As such, one might wonder 
whether restarting the national soil survey program decoupled from a deep-cutting agrarian reform is beneficial
for the general Brazilian population.}}

The efforts of the soil science community have motivated the scientific community to recognize the importance 
of soils for humanity and the environment at the local, regional, and global levels \cite{SanchezEtAl2009, 
Kempen2011, OmutoEtAl2013}. Soil scientists, whose presence in public administration through scientific and 
technical advisory boards appears to grow, seem to have been able to convince policy and decision makers about 
the importance of producing and updating soil information. For example, in Brazil, the Federal Court of 
Accounts (\tcu), in collaboration with Embrapa Soils and other soil science related institutions, held a Soil 
Governance Conference, where a new National Program for Soil Survey and Interpretation of Brazil (\pronassolos)
was announced, with an expected budget of \SI{8}[R\$]~billion\footpronassolos. In the sequence, Embrapa Soils 
created a working group, with soil spatial modellers from other government institutions and universities, and 
the first PRONASOLOS report with proposal and goals was completed on December 2015. Unfortunately, it is not 
clear whether the national soil survey program will truly be restarted because, like happened in the end of the
1980s, it essentially is an economic decision. Apparently, other areas of soil science have not been receiving 
much more attention and/or funding than soil spatial modelling. It is also not clear whether the soil science 
community efforts have brought about a renewed recognition of the importance of soils for humanity and the 
environment among the general public.

\section{MODERN SOIL SPATIAL MODELLING}

Technology plays a determinant role on how we perceive the world around us -- see, for example, 
\citeonline{Hartemink2009}. When early farmers, during the Neolithic Revolution, ca.~\num{10000}~years ago, 
first observed that soil properties varied in space, they probably soon figured out that such variation was 
related to other environmental features and influenced crop yields. That early, rough, approximate 
understanding -- a \emph{model} -- of soil spatial variation certainly was fundamental for choosing -- 
\emph{predicting} -- the most appropriate locations to start and maintain human settlements, some of which 
became great, long-standing empires \cite{MazoyerEtAl2008, BrevikEtAl2010, Churchman2010}. Archaeological 
research provides evidence that several of these empires had more formal \emph{soil classification systems} and 
\emph{soil survey programs}, in most cases for taxation purposes \cite{Barrera-BassolsEtAl2003} -- a practice 
that lasts till today.

\def\footKubrick{\href{https://www.youtube.com/watch?v=qtbOmpTnyOc}{\textit{2001: A Space Odyssey}}}

%% Footnote %%%%%%%%%%%%%%%
\def\footsoil{\footnote{It is common sense among many soil scientists, specially in Brazil, 
that the activity of \emph{soil mapping} concerns the production of \emph{area-class soil maps}, also called 
\emph{polygon soil maps}, \emph{choropleth soil maps}, and more generally \emph{soil maps}. My view is that 
such an understanding, which is rooted in the fact that most early soil mapping projects aimed at producing 
area-class soil maps, is erroneous. Multiple times it results in the confusion between the concept of soil 
itself and that of soil class, soil taxon and/or soil series. In this thesis a soil map is nothing more 
than a graphical representation of the soil. For that end, one has to choose a finite number of properties, 
characteristics, attributes, features of the soil -- the taxonomic classification is one such \emph{feature}. 
Thus, one must bear in mind that, throughout this thesis, the term \emph{soil} is used to mean \emph{soil} -- 
the uppermost layer of unconsolidated material of the Earth's surface... --, not soil class or soil taxon or 
soil series.}}

%% Footnote %%%%%%%%%%%%%%%
% Classes vs. properties: ‘Classes’ are categories of a pre-defined classification system or
% recognized during the survey as natural landscape elements; ‘properties’ are measurable Land
% Characteristics, e.g. soluble salts, or inferred Land Qualities, e.g. toxicity to a specific plant
% variety. \cite{Rossiter2000}

A lot happened since the Neolithic Revolution \cite{BrevikEtAl2010} -- from bone to spacecraft, as in 
Kubrick's \footKubrick --, and the knowledge constructed with multiple soil spatial studies was fundamental 
for the development of agriculture and increase of food production -- although many farmers still live in 
Neolithic conditions \cite{MazoyerEtAl2008}. If we adopt an integrative view, soil maps produced during this 
long period of human history seem to fit into what we call today the \emph{discrete model of spatial 
variation}. The discrete model of spatial variation explains the variation of soil properties in space 
using mutually exclusive mapping units that are separated by sharply defined, crisp boundaries (i.e. polygons) 
\cite{Heuvelink1996, Legros2006}. The soil\footsoil{} within each mapping unit is more or less homogeneous 
with regard to its properties at the time of mapping. These properties, which are generally used to name the 
mapping unit along with other environmental features, can be characterised using one or more direct 
observations made within the domain of the mapping unit \cite{WebsterEtAl1990, Rossiter2000, 
Legros2006}.

\subsection{Discrete Model of Spatial Variation}

A key step was given in 1886 in Russia with the formalization of the approximate understanding of the soil 
spatial variation using scientific parlance, i.e. the postulation of the \q{the basic law of soil science} by 
Vasily Dokuchaev \cite{Florinsky2012}: \q{Any... soil is always and everywhere a mere function of the following 
factors of soil formation: 1) the nature (content and structure) of the parent rock, 2) the climate of the 
given terrain, 3) the mass and character of vegetation, 4) the age of the terrain, and finally, 5) the terrain 
topography.}. The basic law of soil science was presented 40-years later by Sergey Zakharov in the form of a 
general soil formation equation, which is known in the western soil science literature as \cite{Jenny1941, 
Florinsky2012}

\begin{equation}\label{eqn:chap02-clorpt}
 soil = f(cl, o, r, p, t, \ldots),
\end{equation}

\noindent where $soil$ is the soil and its properties, $cl$ if the climate, $o$ are the organisms, including 
humans, $r$ stands for relief or topography, $p$ is the parent material, $t$ is time or age of the terrain, 
and $\ldots$ stand for other unknown players. Dokuchaev was aware that producing empirical evidence to 
corroborate his basic law of soil science was difficult because data on soil formation factors was scarce. 
Besides, it was difficult to numerically express the relation between soil and formation factors. Despite of 
these difficulties, the basic law of soil science was readily adopted by soil spatial modellers because it 
provided a solid basis for explaining the soil spatial variation \cite{Smith1986}.

An important enthusiast and supporter of the use of \autoref{eqn:chap02-clorpt} was Hans Jenny 
(\citeyear{Jenny1941}). He believed that the large volume of already existing soil data/knowledge, which had 
been constructed mostly based on the basic law of soil science, needed to be organized by means of numerical 
laws and quantitative theories -- instead of soil maps, taxonomic classifications, and soil-forming processes 
-- to enable treating it mathematically (i.e. using empirical correlation). For that end, solving 
\autoref{eqn:chap02-clorpt} depended on the soil scientist' skills to select suitable study areas and locations 
for making observations. But the problem continued to be that obtaining data on soil-forming factors was still 
difficult compared to obtaining soil data. It follows that direct application of \autoref{eqn:chap02-clorpt} 
for producing soil maps was impossible because it required soil-forming factors to be exhaustively known 
everywhere \cite{Jenny1941}. Despite the operational difficulties encountered since the postulation of the 
basic law of soil science and definition of \autoref{eqn:chap02-clorpt}, the concept of soil-forming factors 
were employed in most of the subsequent soil spatial studies around the world, resulting in the enhancement of 
taxonomic classifications, theories about soil-forming processes, and production of soil maps using the 
discrete model of spatial variation \cite{Schelling1970, Hudson1992, BockheimEtAl2000, Legros2006, 
KrasilnikovEtAl2009b, HarteminkEtAl2013}.

Soil spatial modelling using the discrete model of spatial variation and the idea that soil properties were 
determined by soil-forming factors had its weaknesses as any other model of spatial variation. Three main 
weaknesses can be pointed out, all of which only were recognized and understood using post-war 
scientific/technological developments \cite{HeuvelinkEtAl2001, McBratneyEtAl2003, ScullEtAl2003}. First, 
\q{soil bodies} were described as discrete, homogeneous entities -- although it was recognized that soil is a 
continuous media whose properties vary from place to place in such a way that nearby locations have more 
similar soil property values than distant locations (spatial autocorrelation) --, implying that the fluxes of 
energy and matter across the landscape had to be understood as being partially homogeneous (within a mapping 
unit), partially discontinuous (between mapping units) processes. Second, the uncertainty (the 
acknowledgement of errors) about mapped soil properties was disregarded, meaning that a single, absolute value 
for each soil property would be attributed to each mapping unit ignoring that soil properties vary from place 
to place and that estimates can be affected by all sorts of errors. Last, but not least, some important soil 
spatial modelling decisions could not be efficiently shared with others by means of formal, explicit knowledge 
because they were largely based on the intuitive, tacit knowledge of soil modellers, i.e. the knowledge that a 
soil modeller has about the soil-landscape relationships and the soil modelling process but that cannot be 
adequately communicated, articulated by verbal (written or spoken) means. This was evidenced, for example, by 
the fact that different soil modellers would produce considerably different soil maps without being able to 
explain why \cite{Legros2006, BazagliaFilhoEtAl2013}.

\subsection{Continuous Model of Spatial Variation}

Different solutions were explored during the post-war to overcome one or another weaknesses of the discrete 
model of spatial variation. Most of these solutions came from the new developments in the fields of 
mathematics, statistics and informatics. For example, those important soil spatial modelling decisions, 
generally taken with basis on the tacit knowledge of the soil modeller, could now be more efficiently 
communicated with others through the use of computers -- provided they had a computer. This is because using a 
computer to produce soil maps requires modelling rules to be formalized in the form of a computer script, 
which is the mean used to establish the communication between the soil modeller (a human being) and the data 
processing environment (a computer).

Some soil modellers also came to understand that the error about the mapped soil property could be 
acknowledged using classical statistical theory. First, the definition of mapping units, which was based on 
the knowledge of the soil-forming factors, needed to be viewed as a modelling exercise that aims at minimizing 
the within-unit variance (and maximizing the between-unit variance) of a soil property \cite{VoltzEtAl1990}. 
This was equivalent to designing controlled agronomic experiments as devised by Ronald Fisher in the United 
Kingdom during the 1920s, by which large plots and blocking are used to deal with the effects of short and 
long-range variation, respectively \cite{WebsterEtAl2007}. In both cases the spatial autocorrelation was 
regarded as being of little importance -- it still is in most agricultural experiments. Then, under the 
assumption of spatial independence within mapping units, the most likely value of a soil property at any one 
point in a given mapping unit would be its mean over the multiple observations made in that mapping unit 
\cite{VoltzEtAl1990, Cressie1993}. It follows that the uncertainty about the value of the mapped soil property
is the same everywhere within a mapping unit, irrespective of the location of existing soil observations 
\cite{Heuvelink1996}. This is because due to statistical independence and constant variance within mapping 
units, the expected error of predicting the value of a soil property at any location with its mean is also the
same everywhere. The only requirement so that the estimated mean and variance would be fair (unbiased) was 
that the location of soil observations be selected using some form of randomization (probability sampling) 
such as it is done in controlled agronomic experiments \cite{deGruijterEtAl1990}.

Those solutions still required describing \q{soil bodies} as discrete, homogeneous entities, and continued 
neglecting the spatial variation and autocorrelation of soil properties. Besides, despite the statistical 
soundness, most soil modellers fiercely rejected to employ random sampling and \emph{design-based} estimation. 
They have always preferred to select observation locations purposively according to their mental model of 
soil-landscape relationships because, from a pedological perspective, this seemed more reasonable. However, 
they were generally unaware of the biasedness of their \emph{model-based} estimates. For other soil spatial 
modellers a solution was to partially ignore the knowledge on soil-forming factors and use a different model 
of spatial variation: the \emph{continuous model of spatial variation}. Accordingly, the main requirement was 
that a soil property be treated as a regionalized variable, the outcome of a random (stochastic) spatial 
process \cite{Cressie1993, Webster2000}. A comprehensive theory of \emph{regionalized variables} was first 
constructed during the 1960s by the French mathematician Georges Matheron, heavily based on earlier studies of 
engineers, mathematician, meteorology and statistician such as the South African Daniel Krige, the Swedish 
Bertil Matérn, the Russian Andrey Kolmogorov, among others \cite{Krige1951, Matern1960, Matheron1965, 
MatheronEtAl1987, Cressie1990, WebsterEtAl2007}.

At first, the proposition of \emph{imagining} the soil as being the result of randomness is awkward (see, for 
example, \autoref{eqn:chap02-clorpt}). However, pondering on the multitude of soil-forming factors and 
processes, and on the complexity of their interactions \cite{BockheimEtAl2010, GrunwaldEtAl2011}, as well as 
on the limitations of the existing knowledge on soil spatial variation, one can easily conclude that soil is a 
chaotic media \cite{Webster2000} -- so why not treat it as such? One only had to \emph{imagine} that the value 
of a soil property observed at a given location simply was one that happened to be recorded by chance among an 
infinitely large number of values that could have been recorded instead \cite{Webster2000}. In other words, 
one had to \emph{imagine} that, if a soil property is recorded multiple times at the same location, the 
recorded values would not necessarily be the same. As such, a soil property at a given location would not be 
described using a single absolute value, but a probability distribution function (PDF), generally the normal 
(Gaussian), characterised by the mean and variance of those \q{recorded} values. Accordingly, to describe the 
fact that soil property values at nearby locations are more similar than at locations further apart -- they 
covary, vary together or jointly -- would require a joint probability distribution function, characterised by 
the covariance \cite{WebsterEtAl1990, Cressie1993}. The obvious difficulty in this approach is that the PDF 
cannot be defined because we usually have one single value recorded at each observation location.

Different from its discrete counterpart, the continuous model of spatial variation takes into account the 
relative location of existing observations when predicting a soil property at a given unobserved location. In 
the simplest case, the most likely value of a soil property in a given location is defined by a constant mean 
computed over all observations made in the mapping region, plus a random variable with mean zero and (spatial) 
covariance that depends only on the separation distance between locations \cite{WebsterEtAl1990, Cressie1993}.
This prediction method is known as the \emph{best linear unbiased predictor} (BLUP), usually called 
\emph{ordinary kriging}. The main idea underlying the continuous model of spatial variation is that soil 
property values at nearby locations are more similar than at locations further apart \cite{WebsterEtAl1990}. 
Thus, we err less if we predict the value of a soil property at a given location with a value observed at a 
nearby location than with a value observed at a distant location. Optimally, because the soil is a continuous 
media and its properties vary in space in an autocorrelated fashion, we make the most accurate prediction 
taking a weighted average of the values recorded at all observation locations, nearby locations receiving 
larger weights than distant locations. In both cases, it follows that the uncertainty about the mapped soil 
property is larger the farther from existing soil observations, i.e. it is spatially varying 
\cite{Cressie1993}.

\subsection{Mixed Model of Spatial Variation}

Availability of general-purpose computers fuelled the use and development of the continuous model of
spatial variation, especially in European, North American, and Oceanian countries
\cite{HeuvelinkEtAl2001, McBratneyEtAl2003, ScullEtAl2003}. But limitations in its prediction
performance and developments in remote sensing and machine-learning algorithms helped many soil
scientists to understand that the continuous model of spatial variation had limitations too. For
instance, it is unable to capture abrupt changes in the values of soil properties that occur, for
example, between agricultural fields, parent materials, land uses, and so on
\cite{SteinEtAl1988, VoltzEtAl1990}. Because, contrary to the discrete model of spatial variation, the
continuous model of spatial variation largely ignores the existing pedological knowledge
\cite{Grunwald2009, Lark2012}. Soil scientists also understood that the discrete model of spatial
variation was more efficient than previously thought \cite{BregtEtAl1987}. First, because it was now
possible to employ Jenny's equation of soil-forming factors for soil mapping using remote sensing
products as surrogates of the factors of soil formation \cite{MooreEtAl1993}. Second, machine-learning
algorithms enabled identifying complex spatial patterns that before could only be identified by an
experienced soil scientist \cite{McKenzieEtAl1999}. The most logical step was to combine the
strengths of both discrete and continuous models of spatial variation into a single model -- the
\emph{mixed model of spatial variation} --, that is, inclusion of the existing pedological
knowledge and consideration of the spatial continuity of soil property values.

The mixed model of spatial variation\footnote{The use that I give to the expression \emph{mixed model of 
spatial variation} in this thesis is approximately equivalent to expressions such as regression-kriging, 
kriging with external drift, universal kriging, hybrid approach for soil mapping, pedometric mapping, digital 
soil mapping, predictive soil mapping, environmental correlation, geostatistical mapping, soil-landscape 
modelling, and so on. As far as I know, soil modellers have not yet reached an agreement on how these 
\q{traditional} expressions should be used, nor what their \q{correct} meaning is. See, for example, 
\citeonline{Hengl2003, McBratneyEtAl2003, ScullEtAl2003}. Because the expression \emph{mixed model of spatial 
variation} has a theoretical basis (other expressions are defined based on operational aspects), I understand 
that its adoption and use is a more appropriate choice.} can be viewed as a generalization of previously 
existing models of spatial variation, by which a soil property $Y(\boldsymbol{s})$ at a given location 
$\boldsymbol{s}$ is modelled as the outcome of a spatial stochastic process \cite{Cressie1993, 
HeuvelinkEtAl2001, LarkEtAl2006}. Accordingly, the model is composed of \emph{fixed} and \emph{random effects}. 
The fixed effects, a deterministic large-scale spatial trend, $m(\boldsymbol{s})$, describes the portion of the 
spatial variation of the soil property that is explained with the factors of soil formation as suggested by the 
empirical correlation calculated using point soil observations and spatially exhaustive covariates\footnote{In 
the statistical literature, the term \emph{covariate} is synonymous to \emph{explanatory variable}, 
\emph{predictor variable}, and \emph{independent variable}, and refers to the variable that, although not being 
of primary interest, is used in a model because it determines the behaviour of the \emph{response variable} or 
\emph{dependent variable} \cite{Everitt2006}. In soil science, a covariate has the same statistical meaning, 
the difference being that they assume a pedological meaning as well, i.e. they are viewed as proxies, 
indicators, substitutes, surrogates, approximations of the soil-forming factors due to the simple fact that the 
soil-forming factors -- the true environmental conditions that helped shape the soil -- are unknown. Covariates 
are defined \emph{spatially exhaustive} when they cover the entire area being modelled, i.e. they are 
exhaustively known in the entire geographic space.}. The random effects, also known as stochastic residuals or 
latent variables, $e(\boldsymbol{s})$, describe the portion of the spatial variation of the soil property that 
cannot be explained with the covariates but is potentially spatially correlated, the form and degree of this 
spatial correlation possibly being interpreted pedologically \cite{Lark2012}. Thus 

\begin{equation}\label{eqn:intro-mixed-model}
Y(\boldsymbol{s}) = m(\boldsymbol{s}) + e(\boldsymbol{s}).
\end{equation}

\autoref{eqn:intro-mixed-model} possesses a great flexibility that facilitates to explore newly developed 
statistical and data-mining methods, generally resulting in better performance than the constituent models 
alone, as well as integrating the existing pedological knowledge provided it is translated into a mathematical 
form \cite{OdehEtAl1994, OdehEtAl1995, Heuvelink1996, McBratneyEtAl2000, HenglEtAl2004, Lopez-GranadosEtAl2005, 
WebsterEtAl2007, Grunwald2009, Lark2012}. These features promoted the rapid popularization of the mixed model 
of spatial variation, and many recent large scale soil-mapping projects already successfully employed the mixed 
model of spatial variation \cite{PoggioEtAl2014, NussbaumEtAl2014, HenglEtAl2015}.
% and the development of the Internet, 

% Unfortunately, along with the success of the mixed model of spatial variation, came a rupture between soil 
% modellers pertaining to different \q{schools}, building a negative atmosphere in many
% countries (see examples from Brazil [\url{https://groups.google.com/forum/#!forum/soil-mapping}] and
% Spain [\url{http://www.madrimasd.org/blogs/universo/2009/10/07/126094}]). On one side, this was
% caused by the (presumptuous) assumption that the mixed model of spatial variation possibly
% represented a \q{paradigm shift} in soil science \cite{McBratneyEtAl2003} and that it is the
% ultimate soil mapping method, superior to all others \cite{MinasnyEtAl2016}. This assumption is
% certainly untrue, specially in many poorer regions where the mixed model of spatial variation seems
% useless because farmers already obtain satisfactory yields and properly manage their soils using
% indigenous/local knowledge
% \cite{Barrera-BassolsEtAl2003, Barrera-BassolsEtAl2006, HillyerEtAl2006, CorreiaEtAl2007, 
% ValeJuniorEtAl2007}.
% Perhaps the strong criticism made against soil scientists that
% refused to adopt the mixed model of spatial variation, using somewhat pejorative arguments
% \cite{HeuvelinkEtAl2001,Mendonca-SantosEtAl2003}, helped building this unfruitful scenario. On
% the other side, soil scientists disliked losing importance in the research field in which they worked for
% decades, perhaps very afraid of the new technological developments due to their poor knowledge of
% mathematics, statistics, and informatics \cite{Webster2001,SamuelRosa2012}.

% Although all that is very common when a new theory or method appears
% \cite{Russell1932, Feyerabend1977, Kuhn2011}, I think we have reached a point in which nothing else
% can be gained by
% playing one soil scientist against the other. Such a (noble) understanding was already shared by
% \citeonline{Jenny1941} when comparing \cited{soil geographers} and \cited{soil functionalists}.

\subsection{Spatial Soil Modelling Steps}

Despite the rapid technological developments observed recently, the activity of modelling the soil remained 
essentially the same throughout human history. Soil maps still serve the same old purpose of representing our 
limited understanding about the spatial
organization of the soil in the natural environment in a simplified manner, as well as giving insights about 
how the soil came to be and how they should be managed \cite{Jenny1941, Hudson1992, Legros2006, 
Blanco-CanquiEtAl2010, Grunwald2010}. For this reason, irrespective of the method/model used to produce soil 
maps, perhaps we should use an (integrative) expression such as \emph{soil spatial modelling} instead of 
picking one of the many currently used.

It follows that, based on the existing body of knowledge on soil spatial modelling and the currently available 
technologies, we should try to define what it constitutes, in practice, the soil spatial modelling activity. A 
suggested general (didactic) sequence of steps that we believe represent what is or should be done in soil 
spatial modelling is presented below.

\begin{description}
\item[Step 1] Identify a reality or problem entity, the geographic region for which
there is a demand of spatial soil information. Target soil properties are appointed as well as the
required accompanying output information (e.g. metadata). Key modelling decisions are taken in this step
such as the support (punctual or areal), spatial resolution (and possibly the cartographic scale),
coordinate reference system, etc. Depending on how well defined the demand is, the model of spatial
variation can also be specified, i.e. discrete, continuous, or mixed. Data policy is discussed (What data
should be public? How to make data public? How to implement the data policy?) and agreed upon. Finally,
the available infrastructure, budget, time, and workforce are specified so that next steps can be
appropriately planned as to fulfil the demand.

\item[Step 2] Develop a conceptual model of pedogenesis, a verbal representation of the
reality or problem entity including the explicit description of soil-forming factors and processes
that determine the spatio-temporal distribution of soil properties. This requires gathering the most
of the existing environmental information contained in scientific articles, technical reports,
books, websites, local knowledge, as well as existing maps of the soil, land use, geology, digital
elevation models, satellite images, aerial photographs, among others. Environmental information is used
to articulate pedogenetic concepts. Provided that any of the existing soil data are available, an
exploratory data analysis can help unravelling soil-landscape relationships. The poorer the volume of
existing environmental information, and the less experienced the soil modeller is, the more
important an exploratory field campaign is to help understanding the existing soil-landscape relationships.

\item[Step 3] Define the model of spatial variation, a translation of the conceptual
model of pedogenesis into a set of possible mathematical representations. Depending on
how well defined the demand was, the model of spatial variation was already specified in
\textbf{Step 1}. Provided the volume of existing environmental information and legacy soil data is
moderate to large and/or the soil modeller is very experienced and/or the available budget
allows carrying out exploratory field campaigns, a single model of spatial variation is
defined, i.e. discrete, continuous, or mixed. Assuming that the mixed model of spatial variation is
chosen, the statistical and/or data-mining models that will be used to represent the discrete
and continuous components are specified, taking into account the feasibility of meeting their
requirements given the available soil data, infrastructure, budget, time, and workforce. If multiple
models or statistical and/or data-mining models are chosen, the pedological and
statistical criteria for identifying the best performing model are defined.

\item[Step 4] Prepare the modelling database, a collection of soil and covariate data
needed to estimate the parameters and test the chosen statistical and/or data-mining
models. If required, this includes preparing a sampling plan with formally defined selection rules,
making properly documented field soil observations, and running replicated laboratory analyses.
Soil data from different sources are harmonized. Covariates are selected using the conceptual model
of pedogenesis and empirical evidence. Both soil and covariate data are assessed regarding the need
for nonlinear transformations to meet the requirements of the chosen statistical and/or
data-mining models, and to improve their empirical correlation. Several of these tasks can be (and
usually are) carried out with the aid of a data processing environment (a computer).

\item[Step 5] Estimate the parameters of the statistical and/or data-mining
models, a task that essentially depends on translating the set of possible mathematical
representations of the conceptual model of pedogenesis into a computer representation, that is, a
computer code or script. Developing a well documented computer code that describes all processing
steps ease re-design, future consistency checks, correction of mistakes, and
dissemination/reproducibility. Calibrated models are evaluated using statistical criteria defined in
\textbf{Step 3} such as goodness-of-fit measures. Best performing models are evaluated regarding their
tenability (pedological evaluation), which includes visually assessing draft soil maps, and how well
they represent the range of possible mathematical models. Failure in this last assessment suggests
that the model requires adjustments, possibly more calibration data, or that it can be discarded.

\item[Step 6] Validate the statistical and/or data-mining models, preferentially
predicting the values of the modelled soil properties at a set of independent, probabilistically
selected observation locations for which the true values are known. If an independent set of
observation locations is unavailable, validation is performed using leave-one-out cross-validation.
The best performing model, selected using the statistical criteria defined in \textbf{Step 3}, is
assumed to be the best mathematical representation of the reality under study. If two or more
models present similar prediction performance and have a considerably different structure, then it
can be assumed that the best mathematical representation of the reality under study is given by the
aggregated version of these models, or parsimony is considered to elect the simpler model with 
fewer variables, steps, rules, etc. If previous steps have already allowed selecting a single best
performing model, statistical validation is used only to assess model accuracy.

\item[Step 7] Make spatial predictions, the application of the best performing
model(s) to predict soil properties values at unvisited locations. If demanded, the uncertainty
about the predicted soil properties values (i.e. the prediction interval) is estimated too.
Maps of the target soil properties as well as the required accompanying output information
(e.g. point soil observations, covariate maps, uncertainty maps, metadata, computer scripts)
are delivered to the users of the soil information, and possibly used to populate a spatial soil
information system, where they are made available for inspection using different visualization
techniques. Provided there is infrastructure, budget, time, and workforce available, modelling
steps can be re-designed and the outputs updated at the user request.

\item[Step 8] Reformulate the conceptual model of pedogenesis, the use
of the knowledge gained during the previous steps until the production of the soil property
maps, which give insights about the reality or problem entity under study, to correct
and/or improve the description of soil-forming factors and processes that determine the
spatio-temporal distribution of soil properties. If demanded, the reformulated conceptual model
of pedogenesis is delivered to the users of the soil information as well to help in scenario analysis
and decision making.
\end{description}

\section{SOURCES OF UNCERTAINTY IN SOIL SPATIAL MODELLING}

Soil spatial models, like any other model, are nothing more than a gross simplification of reality.
This means that soil models are unable to explain the spatio-temporal soil variation in
its entirety, but only a small part of it \cite{Heuvelink1998a, Legros2006}. When we use a
soil-mapping model to produce continuous representations of soil properties across space and/or time,
i.e. soil maps, these continuous representations will inexorably deviate from the \q{truth}. What
the soil map presents is our most likely expectation about the soil properties -- not our
\emph{certainty} about them. The deviation from the \q{truth} is what we call \emph{error}. Many
examples from the soil-mapping literature show that, irrespective of the soil property, soil-mapping
models have a quite variable predictive performance, usually explaining between \SI{15}{\percent}
(or less) and (rarely more than) \SI{75}{\percent} of the soil spatial variation
\cite{MooreEtAl1993, OdehEtAl1994, GesslerEtAl1995, McKenzieEtAl1999, GobinEtAl2001, 
SumflethEtAl2008, SunEtAl2012, ViscarraRosselEtAl2013, NussbaumEtAl2014, HenglEtAl2015,
 GaschEtAl2015, HeungEtAl2016}.

The main reason for a soil map to be in error is that the background knowledge and data used to
construct the soil-mapping model is very limited -- we have to try our best with the available
resources. This means that it will never be possible to construct a model that explains the entire complexity 
of the soil \cite{Tukey1997}, and our knowledge about the soil, and the world as a whole,
will always be only partial \cite{Box1993}. Because we cannot eliminate the uncertainty of a soil
map, they can always be considered as wrong, the difference being that some might be useful
\cite{Box1976}.

\subsection{Soil Data}

Soil modellers aim at producing the most accurate representations of the soil given the
available resources. Thus, a reasonable research program is the identification of the causes for
soil maps being more or less uncertain. For instance, the error that results from making
extrapolations and interpolations to predict soil properties at unvisited locations is an
important source of uncertainty \cite{HeuvelinkEtAl1999, RefsgaardEtAl2006}. In the case of
data-centred soil models, such as the mixed model of spatial variation, these errors are
larger the farther we are from the existing observations. Thus, the most efficient way of reducing
these errors is to increase the number of observations and improve the spatial coverage of the mapping
region \cite{BrusEtAl2007a}. However, most soil-mapping projects must rely on using only soil
data produced many years ago \cite{KempenEtAl2009, HenglEtAl2014, PoggioEtAl2014, 
NussbaumEtAl2014, MulderEtAl2016}, when most sampling locations were chosen by soil 
modellers using non-explicit location rules, usually placing more samples in complex and
less known areas \cite{Rossiter2000}.

On the contrary, if the budget of the soil-mapping project includes (additional) sampling, soil
modellers have to decide upon the number and spatial configuration of the sample
\cite{deGruijterEtAl2006, WebsterEtAl2013}. Unfortunately this is not an easy task, except if the
goal is on modelling very few soil properties that can be rapidly measured using field
sensors, and for which a model of spatial (co)variation can be assumed known \cite{MarchantEtAl2006}.
In most cases, several difficult-to-measure soil properties have to be modelled/mapped, many of
which have a poorly known structure of spatial (co)variation. If using the mixed model of spatial
variation, the chosen spatial sample configuration has to be appropriate for estimating the spatial
trend \cite{HenglEtAl2003a, MinasnyEtAl2006b} and the variogram model
\cite{WarrickEtAl1987, WebsterEtAl1992, Lark2002}, making spatial predictions
\cite{YfantisEtAl1987, WalvoortEtAl2010} and, (cross)validating the model/map \cite{BrusEtAl2011}, four
often conflicting objectives. Besides, one must be careful not to decide upon collecting an insufficient
 or an exaggerated number of soil samples. Under-sampling can result in soil models with large 
uncertainty, while over-sampling can produce modelling benefits that do not outweigh the sampling costs 
\cite{vanGroenigenEtAl1999}.

Soil data may not only poorly cover the geographic and/or feature spaces \cite{HenglEtAl2003a}, but
also have significant laboratory and positional errors \cite{NelsonEtAl2011}. Besides, some soil
properties may naturally contain more errors due to their conceptual definition and analytical
procedures employed. Take particle-size distribution as an example. First, the errors are propagated
to the fraction obtained by difference (silt). Second, pre-treatments, such as organic matter
oxidation, can change mineral structure \cite{MikuttaEtAl2005a}. And third, ignoring that the
particle-size distribution is a compositional datum can introduce bias in the predictions
\cite{LarkEtAl2007}.

\subsection{Covariate Data}

Another important source of uncertainty is the covariate data used to calibrate the soil models. Their 
effect appears as a poor correlation with soil properties being modelled, resulting in poor predictions.
One of the reasons why the covariate data can be poorly correlated with the soil property is the fact
that they also contain varying levels of error \cite{HeuvelinkEtAl1989} which could make them 
poor proxies of the soil forming factors. These errors derive from the various 
methods of data generation, analytical procedures and, inherent characteristics of
each site. For example, digital elevation models usually present larger errors in areas with steep
slopes, rough terrains, and high altitude, and with dense forest cover or urbanized
\cite{Florinsky1998, Toutin2000, FisherEtAl2006}. Interpolation of elevation data using kriging
can produce spurious artefacts \cite{HenglEtAl2009} compared to hydrologically consistent
algorithms \cite{Hutchinson1989}. And stereoscopic correlation techniques produce digital elevation
models with poorer quality than interferometric synthetic aperture radar \cite{HirtEtAl2010}.

The method used to select which covariates to include in the soil spatial model can also be a reason for
soil maps being in more or less error. This is because every method can select considerably different 
sets of covariates, perhaps including a few that are poorly correlated with soil properties. The selection
of covariates is especially important because the number of available (uncertain) covariates is large, 
many of which possibly being statistically redundant. 

A pedologically sound approach for the selection of covariates is the elicitation of the knowledge of a 
few experts \cite{LarkEtAl2007a, MeyerEtAl2001}. An expert is every soil modeller with long-term 
practical experience in soil mapping \cite{MeyerEtAl2001} and deep knowledge of the mapping 
region, as expressed in the conceptual model of pedogenesis, as well as of the soil and covariate data. 
However, it may be that the understanding about the mapping region may be limited to a point that enables
building only a very uncertain conceptual model of pedogenesis. Take for example a geomorphologically 
complex, unstable landscape that consistently suffers from natural and/or anthropogenic alterations. 
Establishing soil-landscape relationships is very difficult in such circumstances, especially if the 
geomorphological complexity is increased as it is rejuvenated \cite{StreckEtAl2008}. Similar uncertainty
regarding the soil-landscape relationships can arise in very old, stable surfaces of the tropics that have gone
through many environmental modifications, but were not affected by Pleistocene glaciations
\cite{MckenzieEtAl2006}. These landscapes commonly have polygenetic soils that present properties
reflecting today and ancient vegetation and climate \cite{PainEtAl1995, Ker1998}. One could wonder 
whether expert soil modellers would be more efficient at identifying the covariates with the highest 
predictive 
power than sound statistical inference in such circumstances.

A commonly used approach to select the covariates to enter a soil-mapping model is automated selection.
Because automated selection algorithms are available in most software packages \cite{Harrell2001a},
they are relatively easy to use \cite{DraperEtAl1971}, deliver satisfactory results,
\cite{HenglEtAl2004}, and are needed to automate soil-mapping routines \cite{HenglEtAl2014}. The
main uncertainty here is on which method to use. Some methods analyse all possible combinations of
covariates. Others simulate the process of natural selection \cite{AndersenEtAl2010}.
Cross-validation selects covariates that produce the best predictions on test sets
\cite{GuyonEtAl2003}. Other methods take into account the order in which the covariates are added
to (forward selection) or removed from (backward elimination) the model \cite{LarkEtAl2007a}. 
The stepwise method adds and removes covariates until no further addition or removal results in
significant changes in the model \cite{DraperEtAl1998}. Many other methods exist and have been
used in soil-mapping projects \cite{PoggioEtAl2013,NussbaumEtAl2014}. Some prefer to use
dimensionality reduction techniques to reduce the number of covariates \cite{Massy1965} before
running the covariate selection algorithm \cite{tenCatenEtAl2011a, HenglEtAl2014}. However, there
are evidences that the number of problems associated with using automated covariate selection
methods, and dimensionality reduction techniques, can be greater than the number of advantages 
\cite{FarrarEtAl1967, Jackson1993, Chatfield1995, Edirisooriya1995, Harrell2001a, Jolliffe2002, 
Peres-NetoEtAl2005, LarkEtAl2007a}. The most evident being the fact that each method produces a
 different set of covariates which may have a weaker physical or biological relation with the soil 
property being modelled.

\subsection{Model Structure}

Soil modellers also have to chose the form of the model that will be used to model the
empirical relation between covariates and soil properties. Early soil-mapping projects were based
solely on mental models \cite{Hudson1992}. Later, many soil-mapping projects used statistical
models that assume a linear relation \cite{MooreEtAl1993, OdehEtAl1994}. Developments in
statistics introduced new forms of modelling this relation. Nowadays many soil-mapping projects
employ machine-learning methods such as regression trees, artificial neural networks, random forests,
support vector machines, among many others \cite{HeungEtAl2016}. The main reason being that these
nonlinear models have a greater ability to capture more complex site-specific soil-landscape relations
\cite{Grunwald2009}.

In fact, the relation between soil properties and covariates seldom is completely linear 
\cite{McKenzieEtAl1999}. For some the fact that each model produces a
different soil map may be seen as a problem, although the validation statistics may suggest that the 
differences in their performance are insignificant \cite{HeungEtAl2016}. A solution is to aggregate 
the predictions of the many models, but this will not necessarily reduce our uncertainty. Besides, 
machine-learning methods are more difficult to implement and interpret \cite{Grunwald2009}, possibly 
being more prone to error.

\section{CONCLUSIONS}

The sources of uncertainty in soil spatial modelling are multiple and the list that has been presented here
is far from being comprehensive -- others will do a better job. The main message is that we cannot 
eliminate the uncertainty of a soil map and, as such, our knowledge about the soil will always
be limited. Despite of this, soil spatial models -- and the entire body of human knowledge -- are still
needed to guide our every-day actions. So, instead of eliminating uncertainty, the real quest is for
understanding it and its sources. If for instance it happens to us to gain knowledge that a source of 
error has a systematic nature, then a corrective measure can be taken right away.

% Because while studying the multiple sources of uncertainty -- the
% \emph{known unknowns} --, instead of bringing them all into light, turning them into sources of 
% error which we have a good understanding of -- the \emph{known knowns} --, we end up uncovering 
% other sources of error that we were not aware of -- the \emph{unknown unknowns} \cite{Wikipedia2015}. 
% If a known (or unknown) unknown happens to become a known known, then action can be taken to 
% reduce our uncertainty. For example, if we gain knowledge that a source of error has a systematic nature, 
% then a corrective measure can be taken right away.

A most comprehensive way of dealing with the multiple sources of uncertainty is \emph{error propagation 
analysis}, also called \emph{uncertainty analysis} \cite{HeuvelinkEtAl1989, Taylor1997}. This is done taking
our uncertainty into account through the modelling steps, seeing how it propagates, and
evaluating its impact on the uncertainty about the output soil map. This would allow us identifying the
main source of uncertainty, so that we could try to take corrective measures to improve its quality.
But such an exercise is cumbersome \cite{NelsonEtAl2011}, and the efforts required may not
outweigh the benefits, this being one of the reasons why it is rarely carried out. Another important
reason for error propagation analysis being unpopular is the common ignorance and lack of
understanding -- perhaps prejudice -- about error and uncertainty \cite{Wechsler2003, Heuvelink2005}.
But the most important reason seems to be that statistical packages and data analysis environments do
not include -- if they ever will or should include -- a simple routine, a button, to run a complete
uncertainty analysis \cite{HeuvelinkEtAl2006b}.

%Since soil maps still are useful, despite being in error, most soil-mapping projects adopt a very
%pragmatic approach, and the uncertainty is almost completely ignored \cite{McBratneyEtAl2003, 
%ScullEtAl2003}.
%In other words, we assume that all sources of uncertainty are insignificant.
%Positional and analytical errors are disregarded, covariates are taken as certain, and so on. These
%data are used to calibrate a few models, whose parameters are assumed to be estimated without error
%\cite{DiggleEtAl1998}. The soil-mapping model with the best validation statistics, generally
%chosen using (the optimistic) cross-validation, is selected to make spatial predictions at unvisited
%locations \cite{BrusEtAl2011}. Errors in the resulting map are regarded as being due to interpolation
%error. Most soil models will output an estimate of this uncertainty, i.e. a measure of what
%we do not know about the modelled/mapped soil property such as the kriging prediction error variance
%\cite{HeuvelinkEtAl1989}. But even such a measure is nothing more than a model of our uncertainty
%whose quality needs proper assessment \cite{Goovaerts2001}. Because soil models that ignore
%the spatial autocorrelation of the prediction errors generally are optimistic about our uncertainty,
%i.e. they estimate that we know more than we actually do. And geostatistical models can either
%under- or overestimate the uncertainty depending on the available data and modelling decisions
%\cite{Lark2000a}.

%Continually ignoring the uncertainty in soil-mapping projects is quite a dangerous choice
%\cite{HeuvelinkEtAl1999}. It can induce the layman -- and even other scientists -- to think that
%soil modellers produce perfect, complete answers to soil-related issues. The most likely
%consequence is what already happened in the end of the 1980's in most countries when funds for
%soil-modelling research were almost completely extinguished
%\cite{Basher1997, Dalmolin1999, Ker1999, Ramos2003, HarteminkEtAl2008, Finke2012}: if the
% soil map is a perfect
%representation of reality, then once it is done, soil modellers become useless. Nowadays, many
%software packages and data analysis environments include a basic routine to take into account, at
%least, one source of uncertainty \cite{ChristensenEtAl2002, Papritz2015, RibeiroJrEtAl2015}. If a
%more elaborated, problem-specific software is required, then there is the free and open source
%software community. Free access to the scientific literature is guaranteed by many governments,
%universities, and libraries that spend a significant amount of resources every year on subscriptions
%and maintenance of digital repositories. Anyone with a true interest in contributing to the body of
%human knowledge must recognize the urgent need to stop neglecting, perhaps consciously denying, 
%what we already known -- the \emph{unknown knowns} \cite{Zizek2006}.

