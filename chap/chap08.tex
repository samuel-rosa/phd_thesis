\artigotrue
\chapter{SAMPLING FOR SOIL MAPPING IN \emph{TERRA INCOGNITA}}
\label{chap:chap08}

\def\ptkeys{}

\begin{chapterabstract}{brazilian}{\ptkeys}

\end{chapterabstract}

\def\enkeys{}
  
\begin{chapterabstract}{english}{\enkeys}

\end{chapterabstract}

\formatchapter

\section{INTRODUCTION}

\titlenote{This chapter is based on the study \textit{spsann -- optimization of sample patterns using spatial 
simulated annealing}, presented at the EGU General Assembly 2015 \cite{Samuel-RosaEtAl2015a}, and 
\textit{Optimization of sample configurations for variogram estimation}, presented at Pedometrics 2015 
\cite{Samuel-RosaEtAl2015c}. Also collaborated in the preparation of this document: Gerard B. M. Heuvelink 
(ISRIC -- World Soil Information), Dick J. Brus (Alterra, Wageningen University and Research Centre, the 
Netherlands), Gustavo M. Vasques (Embrapa Soils, Brazil), and LÃºcia Helena Cunha dos Anjos (Universidade 
Federal Rural do Rio de Janeiro, Brazil).}

The success of soil mapping largely depends on the sampling data because the last are used to 1) estimate the 
spatial trend, 2) estimate the variogram of the residuals, and 3) make spatial predictions by calculating 
conditional distributions. A poor sampling strategy is likely to deliver a poor model and large prediction 
errors, resulting in a waste of financial resources, staff and time \cite{vanGroenigenEtAl1999,  
deGruijterEtAl2006, LanEtAl2010}. This is undesirable because sampling already is the largest contributor to 
the costs of soil mapping \cite{WebsterEtAl1990, vanGroenigenEtAl1999, KempenEtAl2012}.

The focus of this study is on the optimization of spatial sample configurations for soil mapping. We explore a 
scenario in which a) multiple soil properties have to be mapped, b) we are ignorant about the form of the model 
of spatial variation, and c) the operational constraints limit sampling to a single phase. The objective is to 
evaluate the ability of different sampling configuration types and sample sizes to capture the true form of the 
model of spatial variation and make accurate predictions. We also quantify the gain in prediction accuracy by 
combining popular sampling methods in a multi-objective optimization problem. This study addresses a problem 
that many soil scientists involved in soil mapping projects face: how to come up with a spatial sample 
configuration that is effective and robust in situations where we know very little?

\section{PURPOSIVE SAMPLING}

\emph{Purposive sampling} is the non-probability sampling mode by which the sampling locations are selected 
intentionally as to satisfy an \textit{a priori} criterion. This criterion is commonly defined based on the 
model that will be used to infer the structure of spatial variation of a soil property $Y(\boldsymbol{s})$. 
Compared to probability sampling, purposive sampling generally is more efficient for \emph{model-based 
inference} \cite{deGruijterEtAl2006}.

The criterion used to select the sampling locations can be defined based on the chosen statistical model 
\cite{deGruijterEtAl2006, Mueller2007, WebsterEtAl2013}. A set of mathematical and heuristic rules is then 
formalized in the form of a computer algorithm to find the sampling locations that minimize (or maximize) that 
criterion. The more we know about the structure of spatial variation of $Y(\boldsymbol{s})$, the more likely we 
are to obtain the optimum sample configuration given the chosen statistical model.

However, the statistical model is usually unknown before we sample. This is especially common when multiple 
soil properties have to be mapped and the available information is insufficient to decide on the structure of 
the spatial variation. Because we usually want to make the least possible number of assumptions about the model 
structure, the safest solution is to use a space filling design \cite{HenglEtAl2003a, deGruijterEtAl2006, 
Mueller2007, WalvoortEtAl2010}: the locations are selected as to generate a sample that covers the geographic 
and/or feature space(s) as evenly as possible. In areas with very little information on the spatial variation 
of the soil properties of interest, referred to \emph{terra incognita} by \citet{WebsterEtAl2007}, there 
usually are operational constraints that limit the sampling to a single phase. The spatial sample configuration 
has to be optimized to identify the correct model structure, estimate model parameters, and make spatial 
predictions.

\subsection{Sampling for Spatial Trend Estimation}

The spatial trend corresponds to the spatial variation of $Y(\boldsymbol{s})$ that is explained linearly or 
nonlinearly by the covariates. For a linear spatial trend, the sample should cover the extremes of the 
distribution of the covariates \cite{Mueller2007}. For models with interactions and/or higher order terms there 
are the response surface designs \cite{BoxEtAl1951, LeschEtAl1995}. These approaches produce clusters of points 
and ignore the spatial autocorrelation of the residuals \cite{BrusEtAl2007a, Mueller2007}. Optimal sampling 
designs for neural nets, random forests, etc., are yet unknown.

A common solution for spatial trend estimation in \emph{terra incognita} is to use a feature space filling 
sample. \citet{HenglEtAl2003a} sampled along the marginal distribution of the covariates using equal-range 
strata with weights proportional to the frequency distribution. \citet{MinasnyEtAl2007a} sampled equal-variance 
geographic strata created using the variance of the covariates retained in their first principal component.

A more elaborated method, formulated as a multi-objective optimization problem, was developed by 
\citet{MinasnyEtAl2006b} based on the Latin hypercube sampling \cite{McKayEtAl1979}, known as \emph{conditioned 
Latin hypercube sampling} (CLHS). The CLHS is based on sampling along the marginal distribution of the numeric 
and factor covariates using equal-area strata (quantile sampling) and proportionally to the area occupied by 
each level, respectively, and reproducing the linear correlation of the numeric covariates 
\cite{MinasnyEtAl2006b}. The method is very flexible and can be easily extended \cite{MinasnyEtAl2010a, 
RoudierEtAl2012}. Recently, \citet{Samuel-RosaEtAl} proposed conceptual and algorithmic improvements on the 
CLHS. In short, the proposed improvements concern the definition of the marginal sampling strata, the 
measurement of the correlation between covariates, and the aggregation of the objective functions.

\subsection{Sampling for Variogram Estimation}

A variogram model explains the spatially correlated random part of the spatial variation of 
$Y(\boldsymbol{s})$. Several sampling methods exist to identify and/or estimate the variogram and its 
parameters \cite{BrusEtAl1994, deGruijterEtAl2006, Mueller2007, WebsterEtAl2013}. Modern ones focus on maximum 
likelihood estimators \cite{Lark2002, Zimmerman2006, Mueller2007}. Their limitation is that a minimum knowledge 
about the form of the variogram is required. A Bayesian approach was suggested to account for the uncertainty 
of the estimated variogram \cite{DiggleEtAl2006, MarchantEtAl2006, ZhuEtAl2006}. But it is hard to implement 
for multiple variables simultaneously, and the uncertainty is likely to increase with the number of parameters 
that need to be estimated.

Sampling for variogram estimation should concentrate on relevant pairwise distances \cite{MuellerEtAl1999, 
Lark2002}. But how to do that when we are ignorant about the shape of the variogram? \citet{BreslerEtAl1982, 
Russo1984, WarrickEtAl1987} proposed a conservative solution focusing on the method of moments: the points 
should be located as to match a uniform distribution of pairwise distances. Their claim was that the sample 
would be globally optimal for an infinite set of unknown variograms. This has not been proved mathematically 
nor corroborated by empirical evidence. The resulting sample usually is redundant (poorly informative), 
concentrating most of the points in a single large cluster, with a few scattered points -- many of the 
point-pairs are computed using the same subset of points.

\subsection{Sampling for Spatial Interpolation}

Kriging is the best unbiased linear predictor of soil properties \cite{LarkEtAl2006}. The overall prediction 
accuracy depends on spreading the sample points as uniformly as possible throughout the study area. This is 
because for a stationary isotropic random field the kriging variance is a function only of the distance between 
sample points \cite{Cressie1993}. Regular sampling grids are commonly used to obtain a uniform geographic 
coverage, although triangular equilateral grids are more efficient \cite{WebsterEtAl2007}. Regular grids 
usually are inappropriate for irregularly shaped areas \cite{WalvoortEtAl2010}.

The regression-kriging approach for soil mapping \cite{HenglEtAl2007b} lead to the development of sampling 
methods that account for both feature and geographic spaces. \citet{HenglEtAl2003a} proposed sampling 
iteratively in the feature space and keeping the sample configuration with the best geographic coverage. 
\citet{MinasnyEtAl2006b} developed a sampling strategy for spatial trend estimation and claimed that the 
geographic space could be considered as well. \citet{MinasnyEtAl2007a} suggested that a geographic 
stratification based on the variance of the covariates would take into consideration the geographic coverage. 
These methods are suboptimal for spatial interpolation because they essentially operate in the feature space.

Efficient optimization of sample configurations for spatial interpolation depends upon minimizing a 
distance-based metric \cite{RoyleEtAl1998}. One such metric is the Mean Squared Shortest Distance (MSSD) 
between sample and prediction points \cite{BrusEtAl2006}. It is equivalent to finding, for each prediction 
point, the nearest neighbouring sample point. This metric can be minimized using the \textit{k}-means 
clustering algorithm \cite{WalvoortEtAl2010}, which is computationally fast, but sensitive to local optima 
solutions.

\section{PROPOSED INNOVATIONS AND MODIFICATIONS}

We believe that there is room to improve on the existing methods and propose innovations for sampling for soil 
mapping in \emph{terra incognita}. Our proposed innovations and modifications have been implemented in the 
publicly available \Rpackage{spsann} (\url{https://cran.r-project.org/web/packages/spsann}).

\subsection{Sampling for Spatial Trend Estimation}

We consider the method of \cite{MinasnyEtAl2006b} to be the most suited to sample for spatial trend estimation 
for soil mapping in \emph{terra incognita}.

\subsection{Sampling for Variogram Estimation}

We propose that sampling to estimate the variogram model for soil mapping in \emph{terra incognita} should be 
based on placing several small clusters scattered throughout the spatial domain as to maximize the amount of 
information. The most relevant pairwise distances are those that enable an accurate estimate of the behaviour 
of the variogram near the origin. We use exponentially spaced lags defined up to the circumradius $r$ of the 
bounding box of the area. The exponential spacings are created sequentially from the largest to the smallest 
lag by halving the immediately preceding larger lag, resulting in narrower lags in the left side of the 
variogram. It works as follows:

\begin{enumerate}
 \item Find $r$. Use the result to define the upper bound (UB) of the first rightmost lag.
 \item Halve $r$. Use the result to define the lower bound (LB) of the first rightmost lag.
 \item Go to the next lag.
 \item Set the LB of the last lag as the UB of the current lag.
 \item Halve the UB. Use the result to define the LB of the current lag.
 \item Proceed as in 3--5 till the UB and LB of leftmost lag have been defined.
\end{enumerate}


We define seven exponentially spaced lag-distance classes up to half the 
diagonal of the spatial domain. They are created sequentially by halving the immediately preceding larger lag 
\cite{TruongEtAl2013}. Our objective is to place the points as to have each of them contributing to all lags. 
The criterion to be minimized is the sum of differences between the vectors of the pre-specified 
$\boldsymbol{l}^*$ and observed $\boldsymbol{l}$ distributions of unique \textbf{P}oints \textbf{P}er 
\textbf{L}ag

\begin{equation}
 \text{PPL} = \sum_{i = 1}^{n} w_i (l_i^* - l_i),
\end{equation}\label{eq:chap08-ppl}

\noindent where $\boldsymbol{w}$ is a vector of weights for the $n$ lag-distance classes.

\subsection{Sampling for Spatial Interpolation}

The MSSD seems to be the most suited criterion to optimize sample configurations for spatial interpolation for 
soil mapping in \emph{terra incognita}. However, the available algorithms cannot be used to formulate 
multi-objective optimization problems. We suggest using the spatial simulated annealing algorithm instead, 
eliminating the sensitivity to local optima solutions \cite{KirkpatrickEtAl1983, Groenigen1999a}.

\subsection{Sampling for Soil Mapping in \emph{Terra Incognita}}

We propose a heuristic, general-purpose method to design sample configurations for soil mapping in \emph{terra 
incognita}. Like sampling for spatial trend estimation, it is based on solving a MOOP. An utility function is 
defined aggregating the four objective functions described above so that the sample points SPAN the feature, 
variogram and geographic spaces,

\begin{equation}
\text{SPAN} = w_1 \text{CORR} + w_2 \text{DIST} + w_3 \text{PPL} + w_4 \text{MSSD}, 
\end{equation}\label{eq:chap08-span}

with $w_1 = w_2$ and $w_1 + w_2 = w_3 + w_4$ in the \emph{terra incognita} setting.

\section{CASE STUDY}

The study was developed using synthetic data derived from a real-world study case described by 
\citet{Samuel-RosaEtAl2015}. The study site is a small catchment of about \SI{2000}{\hectare} located on the 
southern edge of the plateau of the ParanÃ¡ Sedimentary Basin, Rio Grande do Sul, Brazil 
(\autoref{fig:chap08-location}). The real-world dataset contains $n = 350$ point soil observations of the 
topsoil, and includes several soil properties, but only two were explored in this study: clay content (CLAY, 
\si{\gram\pre\kilo\gram}) and bulk density (BUDE, \si{\mega\gram\per\cubic\metre}). The dataset also includes 
several covariates derived from area-class soil maps, digital elevation models, geological maps, land use maps, 
and satellite images. All preprocessing steps and methods used to derive the covariates were described by 
\citet{Samuel-RosaEtAl2015}.

\begin{figure}[!ht]
 \centering
 \includegraphics[draft = true, width = 90mm]{fig/chap08-location}
 \caption{Location of the real-world study area in Santa Maria, southern Brazil.}
 \label{fig:chap08-location}
\end{figure}

\subsection{Soil Data Generating Process}

We assumed the soil properties ($Y$) to be a function of the interplay of environmental conditions defined by 
the climate, organisms, relief, parent material, time, and other unknown players \cite{Jenny1994, 
McBratneyEtAl2003, Florinsky2012}. Because our pedologial knowledge and data available still are too limited 
to build such a complex \emph{mechanistic model}, we assumed the soil properties to be the outcome of a 
spatial stochastic process composed of the additive combination of fixed and random effects, i.e. 
$Y(\boldsymbol{s}) = m(\boldsymbol{s}) + e(\boldsymbol{s})$. Here the soil property is a random variable 
$Y(\boldsymbol{s})$, $m(\boldsymbol{s})$ is a deterministic trend, and $e(\boldsymbol{s})$ is a spatially 
correlated, Gaussian distributed random variable, that is stationary in the mean and covariance 
\cite{HeuvelinkEtAl2001}.

Using the above formulation of the \emph{mixed model of spatial variation}, we defined two \emph{soil 
data generating processes} assuming a different form in $m(\bolsymbol{s})$ and $e(\boldsymbol{s})$. In 
practice, we used the real-world soil data to calibrate (non)linear mixed models that are taken as the exact 
mathematical representations of the true (stochastic) processes giving rise to the soil and its properties. 
The linear mixed model is that constructed by \citet{Samuel-RosaEtAl2015} using CLAY ($n = 350$) in the 
Box-Cox space due to its strong skewness, and corresponds to what the authors called their \emph{best 
performing} linear mixed model. The non-linear mixed model was constructed by \citet{Samuel-RosaEtAl} using 
BUDE ($n = 282$) in its original untransformed scale, the non-linear trend being defined using the out-of-bag 
predictions of a random regression forest model. The spatially dependent stochastic residuals of CLAY and BUDE 
were modelled using the Whittle-MatÃ©rn model, the difference being that the shape parameter was set to $\nu = 
(0.5, 2)$, respectively. All model parameters were estimated by Gaussian restricted maximum likelihood (REML) 
\cite{LarkEtAl2004, DiggleEtAl2007}. Both models also differ by the spatially correlated variance (SCV) of the 
stochastic residuals, which is small for BUDE ($\text{SCV} \cong 0.20$) and large for CLAY ($\text{SCV} \cong 
0.85$).

Sequential unconditional Gaussian simulation was used to create $\mathcal{R} = 1000$ equiprobable realizations 
of each soil data generating process with linear and non-linear trends (\autoref{fig:chap08-realizations}) as 
described in \autoref{subsec:simulation} \cite{Samuel-RosaEtAl}.
 
\begin{figure}[!ht]
 \centering
 \includegraphics[draft = true, width = \textwidth]{fig/chap08-realizations}
 \caption{Example realizations of the soil data generating processes with a) linear and b) non-linear trends.}
 \label{fig:chap08-realizations}
\end{figure}

\subsection{Sampling Scenarios}

We defined $\mathcal{A} = 6$ sampling designs with $\mathcal{N} = 3$ sample sizes $n = (100, 200, 400)$. These 
sample sizes correspond to the moderately high inspection density (1 sample point per 20, 10, and 
\SI{5}{\hectare}, respectively) recommended for the production of soil maps published at a \scale{25000} 
\cite{Rossiter, 2000}. The baseline design was obtained by simple random sampling (SRS), which we understand as 
the poorest sampling design. The second sampling design was obtained by systematic grid sampling (SGS), one of 
the most commonly used sampling design for soil mapping.

Another three sampling designs were defined minimizing each of the three criteria pointed above: ACDC, PPL, and 
MSSD. Our multi-objective sampling design was obtained minimizing the three criteria simultaneously (SPAN). 
Since we assumed to be ignorant about the structure of the soil data generating processes, all criteria were 
considered equally important and received the same weights. Note that for ACDC and SPAN, different sample 
configurations were optimized for CLAY and BUDE because the algorithms use the same set of covariates used to 
calibrate the soil data generating processes.

The combination of sampling designs and sample sizes resulted in 18~point sample sets. Each of these point 
sample sets were used to sample from the $\mathcal{R} = 1000$ simulated realities of CLAY and BUDE. This 
yielded \num{36000}~calibration datasets. The baseline designs were used to quantify the gain in prediction 
accuracy with the use of our multi-objective sampling design.

We also defined the true optimum sampling design for CLAY. In this case we assumed the structure of the CLAY 
data generating process to be known. The criterion minimized was the mean universal kriging variance 
\cite{BrusEtAl2007a}. The optimum design was also explored at three sample sizes and used to sample from the 
$\mathcal{R} = 1000$ simulated realities of CLAY with linear trend. This yielded another 3000~calibration 
datasets. The true optimum sampling designs was used to quantify how suboptimal our multi-objective sampling 
design is.

\subsection{Evaluation of Sampling Algorithms}

We will evaluated how sampling design and sample size influence spatial prediction accuracy. The goal will be 
to evaluate how our multi-objective sampling design compares with the baseline designs. For the spatial 
stochastic process with linear trend, we will also compared our multi-objective sampling design with the true 
optimum design. For these purposes, the same evaluation strategy used by \cite{Samuel-RosaEtAl} will be 
employed.

The variation in model parameter estimation will also be evaluated for both linear mixed model and 
regression-kriging model plotting together the 1000 variogram models calibrated with each sampling design and 
sample size superimposed by the true variogram model. The variation of each variogram model parameter will be 
summarized using box-and-whisker plots. For the regression-kriging model, box-and-whisker plots will be used 
to summarize the variation of the importance ranking of each predictor variable. For the linear mixed model, 
we will summarize the coefficients of the linear trend. These statistics will be compared with the true model 
parameters.

\section{FINAL CONSIDERATIONS}

The main free and open source implementation of the CLHS is the \Rpackage{clhs} \cite{RoudierEtAl2012}. The 
package extended the CLHS considering the use of a cost surface that penalizes sampling locations that are 
difficult to access. Other researchers have also implemented the CLHS as to consider a cost function 
\cite{MulderEtAl2013, CliffordEtAl2014}, but none is available as a free software package.
